{"cells":[{"cell_type":"markdown","id":"e5O7e2rsGYxt","metadata":{"id":"e5O7e2rsGYxt"},"source":["# Import Libraries"]},{"cell_type":"code","execution_count":1,"id":"d46366e0","metadata":{"id":"d46366e0"},"outputs":[],"source":["import os\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import itertools\n","\n","from imblearn.over_sampling import SMOTE, ADASYN\n","from imblearn.under_sampling import RandomUnderSampler\n","from imblearn.combine import SMOTEENN, SMOTETomek\n","from imblearn.pipeline import make_pipeline, Pipeline\n","\n","from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.preprocessing import FunctionTransformer\n","\n","### Classifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import KFold \n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.naive_bayes import GaussianNB \n","\n","from sklearn.metrics import confusion_matrix,auc,roc_auc_score, ConfusionMatrixDisplay\n","from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\n","\n","import collections"]},{"cell_type":"code","execution_count":2,"id":"0dd4bc00","metadata":{"id":"0dd4bc00"},"outputs":[],"source":["import warnings\n","from sklearn.exceptions import ConvergenceWarning, FitFailedWarning\n","warnings.simplefilter(action=\"ignore\", category=UserWarning)\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.simplefilter(action=\"ignore\", category=ConvergenceWarning)\n","warnings.simplefilter(action=\"ignore\", category=FitFailedWarning)"]},{"cell_type":"markdown","id":"60f3746a","metadata":{"id":"60f3746a"},"source":["# Helper Functions"]},{"cell_type":"code","execution_count":3,"id":"19026070","metadata":{"id":"19026070"},"outputs":[],"source":["def get_data_by_class(data):\n","    fraud = data[data.Class==1]\n","    not_fraud = data[data.Class==0]\n","\n","    return fraud, not_fraud"]},{"cell_type":"code","execution_count":4,"id":"e40fa669","metadata":{"id":"e40fa669"},"outputs":[],"source":["def eliminate_extreme_amount(data, col='Amount', threshold=3000):\n","    new_data = data[(data[col] <= threshold)].copy()\n","\n","    return new_data"]},{"cell_type":"code","execution_count":5,"id":"197e3b5d","metadata":{"id":"197e3b5d"},"outputs":[],"source":["def stratified_train_test_byclass(data, feature_names, by, test_size=0.3):\n","    ## convert seconds to hour, assign this info to a new column\n","    to_hour = np.floor(data.Time/(60*60)).astype(int)\n","    for t in range(len(to_hour)):\n","        if to_hour[t] >= 24:\n","            to_hour[t] = to_hour[t] - 24\n","\n","    data['TimeHour'] = to_hour\n","\n","    X = data.drop('Class', axis=1).copy()\n","    y = data[class_name]\n","\n","    X_train, X_test, y_train, y_test = \\\n","        train_test_split(X, y, test_size=test_size, random_state=1, stratify=data[by])\n","\n","    X_train.drop('TimeHour', axis=1, inplace=True)\n","    X_test.drop('TimeHour', axis=1, inplace=True)\n","\n","    return X_train, X_test, y_train, y_test"]},{"cell_type":"code","execution_count":6,"id":"0631cbdf","metadata":{"id":"0631cbdf"},"outputs":[],"source":["import matplotlib.gridspec as gridspec\n","\n","def draw_density_curve(data):\n","    frauds = data.Class == 1\n","    normals = data.Class == 0\n","\n","    grid = gridspec.GridSpec(10, 3)\n","    plt.figure(figsize=(15,30))\n","\n","    for i, col in enumerate(data[feature_names[1:-1]]): #exclude Time and Amount\n","        ax = plt.subplot(grid[i])\n","        sns.distplot(data[col][frauds], bins = 50, color='g')\n","        sns.distplot(data[col][normals], bins = 50, color='r')\n","        ax.set_ylabel('Density')\n","        ax.set_title(str(col))\n","        ax.set_xlabel('')\n","    plt.show()"]},{"cell_type":"code","execution_count":7,"id":"d44b6fa1","metadata":{"id":"d44b6fa1"},"outputs":[],"source":["def draw_boxplot(data, feature_names, img_size=(15,15)):\n","    fig, axes = plt.subplots(nrows=4, ncols=6,figsize=img_size)\n","    count_row = 0\n","    count_col = 0\n","\n","    for i in range(len(feature_names)):\n","        sns.boxplot(ax=axes[count_row, count_col], data=data,\n","                    x='Class', y=feature_names[i], palette='Spectral')\n","        if count_col == 5:\n","            count_col = 0\n","            count_row += 1\n","        else:\n","            count_col += 1\n","\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"code","execution_count":8,"id":"5f79b4f5","metadata":{"id":"5f79b4f5"},"outputs":[],"source":["def model_eval_recall(model, X, y):\n","    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n","    scores = cross_val_score(model, X, y, scoring='recall', cv=cv, n_jobs=-1)\n","\n","    return np.mean(scores)\n","\n","def confusion_mtx(y_true, y_pred, title=\"\"):\n","    cf_mtx = confusion_matrix(y_true, y_pred)\n","    print(cf_mtx)\n","    print(classification_report(y_true,y_pred))"]},{"cell_type":"code","execution_count":9,"id":"78e7087d","metadata":{"id":"78e7087d"},"outputs":[],"source":["def log_transform(data):\n","    epsilon = 0.001\n","    data.Amount = np.log(data.Amount + epsilon)\n","\n","    return data\n","\n","log_transform = FunctionTransformer(log_transform)"]},{"cell_type":"code","execution_count":10,"id":"5f45f629","metadata":{},"outputs":[],"source":["def get_predictions(clf, X_train, y_train, X_test): \n","    '''\n","    train model according to the specified classifier\n","    \n","    input: \n","        clf: classifier (as imported from sklearn module)\n","        X_train: training observations \n","        y_train: label for training observations \n","        X_test: test observations \n","    output: \n","        y_predict: predicted label for the test observations \n","        y_predict_proba: predicted class probability for the test observations\n","    '''\n","    # create classifier\n","    clf = clf \n","    # fit classifier to training data \n","    clf.fit(X_train, y_train)\n","    # predict on test data \n","    y_predict = clf.predict(X_test)\n","    # compute predicted probability \n","    y_predict_proba = clf.predict_proba(X_test)\n","    return y_predict, y_predict_proba"]},{"cell_type":"code","execution_count":11,"id":"064a72ed","metadata":{},"outputs":[],"source":["def print_scores(y_test, y_predict, y_predict_proba):\n","    '''\n","    print the scores\n","    '''\n","    print(\"test set confusion matrix:\\n\", confusion_matrix(y_test, y_predict))\n","    print(\"recall score: \", recall_score(y_test, y_predict))\n","    print(\"precision score: \", precision_score(y_test,y_predict))\n","    print(\"accuracy score: \", accuracy_score(y_test, y_predict))\n","    print(\"f1 score: \", f1_score(y_test,y_predict))\n","    print(\"ROC AUC: {}\".format(roc_auc_score(y_test, y_predict_proba[:,1])))\n","\n","    return precision_score(y_test,y_predict), recall_score(y_test, y_predict)"]},{"cell_type":"markdown","id":"5a483217","metadata":{"id":"5a483217"},"source":["**Comment 1:** Eliminate features that show the (approx) same density curve between `Fraud` and `Not Fraud`: V15, V20, V22, V24, V25, V26, V28.\n","\n","**Comment 2:** Most of the remaining features expect for Time, Amount, and V1 of the class `Not Fraud` (red color) are approximately formed as Normal Distribution. As we have a lots of data for this class, we may want to drop some **extreme outliers** so that our data satisfies the assumptions of learning models such as Logistic Regression."]},{"cell_type":"code","execution_count":12,"id":"dd1d3528","metadata":{"id":"dd1d3528"},"outputs":[],"source":["def drop_feature(data, remove=['V13', 'V15', 'V22', 'V24', 'V25', 'V26', 'Time']):\n","    return data.drop(remove, axis=1)\n","\n","drop_feature = FunctionTransformer(drop_feature)"]},{"cell_type":"code","execution_count":13,"id":"d2e1b15c","metadata":{"id":"d2e1b15c"},"outputs":[],"source":["def outlier_removal(data):\n","    fraud, not_fraud = get_data_by_class(data)\n","    feature_names = data.columns\n","\n","    Q1 = not_fraud[np.setdiff1d(feature_names, ['Amount', 'V1'])].quantile(0.25)\n","    Q3 = not_fraud[np.setdiff1d(feature_names, ['Amount', 'V1'])].quantile(0.75)\n","    IQR = Q3 - Q1\n","    lower_whisker = Q1 - 2.5 * IQR\n","    higher_whisker = Q3 + 2.5 * IQR\n","\n","    extreme = not_fraud[((not_fraud < lower_whisker) |(not_fraud > higher_whisker)).any(axis=1)]\n","    not_fraud = not_fraud[~((not_fraud < lower_whisker) |(not_fraud > higher_whisker)).any(axis=1)]\n","\n","    data = pd.concat([fraud, not_fraud]).reset_index(drop=True)\n","\n","    return data, extreme"]},{"cell_type":"code","execution_count":14,"id":"93936280","metadata":{"id":"93936280"},"outputs":[],"source":["def robust_scaler(X_train_transform, X_test_transform):\n","    scaler = RobustScaler()\n","    features = X_train_transform.columns\n","\n","    X_train_transform = scaler.fit_transform(X_train_transform)\n","    X_test_transform = scaler.fit_transform(X_test_transform)\n","\n","    X_train_transform = pd.DataFrame(X_train_transform, columns=features)\n","    X_test_transform = pd.DataFrame(X_test_transform, columns=features)\n","\n","    return X_train_transform, X_test_transform"]},{"cell_type":"markdown","id":"8f0ef352","metadata":{"id":"8f0ef352"},"source":["# Preprocessing data"]},{"cell_type":"markdown","id":"O4I9TjigMY9a","metadata":{"id":"O4I9TjigMY9a"},"source":["## Load data"]},{"cell_type":"code","execution_count":15,"id":"528482f1","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"executionInfo":{"elapsed":6950,"status":"ok","timestamp":1689938490303,"user":{"displayName":"Linh Vu","userId":"10863104398479265021"},"user_tz":-420},"id":"528482f1","outputId":"28f12a26-02ab-4c1a-9455-2427fccc326c"},"outputs":[{"name":"stdout","output_type":"stream","text":["(284807, 31)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Time</th>\n","      <th>V1</th>\n","      <th>V2</th>\n","      <th>V3</th>\n","      <th>V4</th>\n","      <th>V5</th>\n","      <th>V6</th>\n","      <th>V7</th>\n","      <th>V8</th>\n","      <th>V9</th>\n","      <th>...</th>\n","      <th>V21</th>\n","      <th>V22</th>\n","      <th>V23</th>\n","      <th>V24</th>\n","      <th>V25</th>\n","      <th>V26</th>\n","      <th>V27</th>\n","      <th>V28</th>\n","      <th>Amount</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>-1.359807</td>\n","      <td>-0.072781</td>\n","      <td>2.536347</td>\n","      <td>1.378155</td>\n","      <td>-0.338321</td>\n","      <td>0.462388</td>\n","      <td>0.239599</td>\n","      <td>0.098698</td>\n","      <td>0.363787</td>\n","      <td>...</td>\n","      <td>-0.018307</td>\n","      <td>0.277838</td>\n","      <td>-0.110474</td>\n","      <td>0.066928</td>\n","      <td>0.128539</td>\n","      <td>-0.189115</td>\n","      <td>0.133558</td>\n","      <td>-0.021053</td>\n","      <td>149.62</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>1.191857</td>\n","      <td>0.266151</td>\n","      <td>0.166480</td>\n","      <td>0.448154</td>\n","      <td>0.060018</td>\n","      <td>-0.082361</td>\n","      <td>-0.078803</td>\n","      <td>0.085102</td>\n","      <td>-0.255425</td>\n","      <td>...</td>\n","      <td>-0.225775</td>\n","      <td>-0.638672</td>\n","      <td>0.101288</td>\n","      <td>-0.339846</td>\n","      <td>0.167170</td>\n","      <td>0.125895</td>\n","      <td>-0.008983</td>\n","      <td>0.014724</td>\n","      <td>2.69</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>-1.358354</td>\n","      <td>-1.340163</td>\n","      <td>1.773209</td>\n","      <td>0.379780</td>\n","      <td>-0.503198</td>\n","      <td>1.800499</td>\n","      <td>0.791461</td>\n","      <td>0.247676</td>\n","      <td>-1.514654</td>\n","      <td>...</td>\n","      <td>0.247998</td>\n","      <td>0.771679</td>\n","      <td>0.909412</td>\n","      <td>-0.689281</td>\n","      <td>-0.327642</td>\n","      <td>-0.139097</td>\n","      <td>-0.055353</td>\n","      <td>-0.059752</td>\n","      <td>378.66</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>-0.966272</td>\n","      <td>-0.185226</td>\n","      <td>1.792993</td>\n","      <td>-0.863291</td>\n","      <td>-0.010309</td>\n","      <td>1.247203</td>\n","      <td>0.237609</td>\n","      <td>0.377436</td>\n","      <td>-1.387024</td>\n","      <td>...</td>\n","      <td>-0.108300</td>\n","      <td>0.005274</td>\n","      <td>-0.190321</td>\n","      <td>-1.175575</td>\n","      <td>0.647376</td>\n","      <td>-0.221929</td>\n","      <td>0.062723</td>\n","      <td>0.061458</td>\n","      <td>123.50</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2.0</td>\n","      <td>-1.158233</td>\n","      <td>0.877737</td>\n","      <td>1.548718</td>\n","      <td>0.403034</td>\n","      <td>-0.407193</td>\n","      <td>0.095921</td>\n","      <td>0.592941</td>\n","      <td>-0.270533</td>\n","      <td>0.817739</td>\n","      <td>...</td>\n","      <td>-0.009431</td>\n","      <td>0.798278</td>\n","      <td>-0.137458</td>\n","      <td>0.141267</td>\n","      <td>-0.206010</td>\n","      <td>0.502292</td>\n","      <td>0.219422</td>\n","      <td>0.215153</td>\n","      <td>69.99</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 31 columns</p>\n","</div>"],"text/plain":["   Time        V1        V2        V3        V4        V5        V6        V7  \\\n","0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n","1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n","2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n","3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n","4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n","\n","         V8        V9  ...       V21       V22       V23       V24       V25  \\\n","0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n","1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n","2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n","3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n","4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n","\n","        V26       V27       V28  Amount  Class  \n","0 -0.189115  0.133558 -0.021053  149.62      0  \n","1  0.125895 -0.008983  0.014724    2.69      0  \n","2 -0.139097 -0.055353 -0.059752  378.66      0  \n","3 -0.221929  0.062723  0.061458  123.50      0  \n","4  0.502292  0.219422  0.215153   69.99      0  \n","\n","[5 rows x 31 columns]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# pj_path = os.getcwd() ## get current path\n","# data_path = os.path.join(pj_path, 'creditcard.csv')\n","data_path = '/home/phuong/Downloads/stats learning/project data science/creditcard.csv'\n","raw = pd.read_csv(data_path) # load data from the given csv file\n","\n","## get feature and class names\n","all_cols = raw.columns\n","feature_names = raw.columns[:-1]\n","class_name = raw.columns[-1]\n","\n","print(raw.shape)\n","raw.head()"]},{"cell_type":"markdown","id":"ec8c8f49","metadata":{},"source":["## Splitting raw data "]},{"cell_type":"code","execution_count":16,"id":"3d1e4d50","metadata":{},"outputs":[],"source":["X_train_raw, X_test_raw, y_train_raw, y_test_raw = \\\n","    stratified_train_test_byclass(raw, feature_names, [class_name, 'TimeHour'])\n"]},{"cell_type":"markdown","id":"19449bf7","metadata":{},"source":["### Transform raw data"]},{"cell_type":"code","execution_count":17,"id":"22ef9143","metadata":{},"outputs":[],"source":["from copy import deepcopy\n","\n","transformer = Pipeline([('logAmount', log_transform),\n","                        ('dropFeatures', drop_feature)])\n","\n","X_train_raw_transform = transformer.fit_transform(deepcopy(X_train_raw))\n","X_test_raw_transform = transformer.transform(deepcopy(X_test_raw))"]},{"cell_type":"code","execution_count":18,"id":"d78fda50","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>V1</th>\n","      <th>V2</th>\n","      <th>V3</th>\n","      <th>V4</th>\n","      <th>V5</th>\n","      <th>V6</th>\n","      <th>V7</th>\n","      <th>V8</th>\n","      <th>V9</th>\n","      <th>V10</th>\n","      <th>...</th>\n","      <th>V16</th>\n","      <th>V17</th>\n","      <th>V18</th>\n","      <th>V19</th>\n","      <th>V20</th>\n","      <th>V21</th>\n","      <th>V23</th>\n","      <th>V27</th>\n","      <th>V28</th>\n","      <th>Amount</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.315744</td>\n","      <td>-0.022560</td>\n","      <td>0.781190</td>\n","      <td>0.316693</td>\n","      <td>0.029852</td>\n","      <td>0.044179</td>\n","      <td>0.340706</td>\n","      <td>-0.239550</td>\n","      <td>0.214786</td>\n","      <td>-0.827989</td>\n","      <td>...</td>\n","      <td>0.348428</td>\n","      <td>0.722665</td>\n","      <td>0.794576</td>\n","      <td>0.428187</td>\n","      <td>1.786105</td>\n","      <td>0.281148</td>\n","      <td>0.618446</td>\n","      <td>-0.300491</td>\n","      <td>-0.302631</td>\n","      <td>0.677131</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.925438</td>\n","      <td>0.029940</td>\n","      <td>-1.020945</td>\n","      <td>0.254271</td>\n","      <td>0.373978</td>\n","      <td>-0.455245</td>\n","      <td>0.087605</td>\n","      <td>-0.395965</td>\n","      <td>0.525706</td>\n","      <td>-0.269549</td>\n","      <td>...</td>\n","      <td>0.327908</td>\n","      <td>0.582459</td>\n","      <td>-0.175757</td>\n","      <td>0.122565</td>\n","      <td>-0.373306</td>\n","      <td>-0.851116</td>\n","      <td>1.097206</td>\n","      <td>-0.421438</td>\n","      <td>-0.339957</td>\n","      <td>-0.923106</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-1.298557</td>\n","      <td>-0.463563</td>\n","      <td>-0.113693</td>\n","      <td>1.095429</td>\n","      <td>-0.775344</td>\n","      <td>0.796296</td>\n","      <td>0.988980</td>\n","      <td>0.618315</td>\n","      <td>-0.077789</td>\n","      <td>0.416724</td>\n","      <td>...</td>\n","      <td>-0.670524</td>\n","      <td>0.639812</td>\n","      <td>-0.128875</td>\n","      <td>1.056363</td>\n","      <td>-0.761454</td>\n","      <td>-0.550586</td>\n","      <td>-2.955878</td>\n","      <td>7.777107</td>\n","      <td>-3.755432</td>\n","      <td>1.145135</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.525225</td>\n","      <td>0.242929</td>\n","      <td>0.137721</td>\n","      <td>0.455537</td>\n","      <td>-0.137251</td>\n","      <td>-0.414776</td>\n","      <td>0.053385</td>\n","      <td>-0.334183</td>\n","      <td>-0.105175</td>\n","      <td>-0.274301</td>\n","      <td>...</td>\n","      <td>-0.035093</td>\n","      <td>0.432304</td>\n","      <td>-1.005410</td>\n","      <td>-0.753789</td>\n","      <td>0.057693</td>\n","      <td>-0.470065</td>\n","      <td>0.632124</td>\n","      <td>0.005647</td>\n","      <td>0.170056</td>\n","      <td>-0.961741</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.252712</td>\n","      <td>-0.276477</td>\n","      <td>-0.348813</td>\n","      <td>-1.492189</td>\n","      <td>0.326320</td>\n","      <td>-0.347007</td>\n","      <td>0.698994</td>\n","      <td>-0.569688</td>\n","      <td>-0.621672</td>\n","      <td>0.374185</td>\n","      <td>...</td>\n","      <td>1.365126</td>\n","      <td>-0.507564</td>\n","      <td>-0.816685</td>\n","      <td>-0.014495</td>\n","      <td>0.263432</td>\n","      <td>1.161720</td>\n","      <td>-0.911299</td>\n","      <td>2.220866</td>\n","      <td>1.635673</td>\n","      <td>0.715806</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 23 columns</p>\n","</div>"],"text/plain":["         V1        V2        V3        V4        V5        V6        V7  \\\n","0 -0.315744 -0.022560  0.781190  0.316693  0.029852  0.044179  0.340706   \n","1  0.925438  0.029940 -1.020945  0.254271  0.373978 -0.455245  0.087605   \n","2 -1.298557 -0.463563 -0.113693  1.095429 -0.775344  0.796296  0.988980   \n","3  0.525225  0.242929  0.137721  0.455537 -0.137251 -0.414776  0.053385   \n","4 -0.252712 -0.276477 -0.348813 -1.492189  0.326320 -0.347007  0.698994   \n","\n","         V8        V9       V10  ...       V16       V17       V18       V19  \\\n","0 -0.239550  0.214786 -0.827989  ...  0.348428  0.722665  0.794576  0.428187   \n","1 -0.395965  0.525706 -0.269549  ...  0.327908  0.582459 -0.175757  0.122565   \n","2  0.618315 -0.077789  0.416724  ... -0.670524  0.639812 -0.128875  1.056363   \n","3 -0.334183 -0.105175 -0.274301  ... -0.035093  0.432304 -1.005410 -0.753789   \n","4 -0.569688 -0.621672  0.374185  ...  1.365126 -0.507564 -0.816685 -0.014495   \n","\n","        V20       V21       V23       V27       V28    Amount  \n","0  1.786105  0.281148  0.618446 -0.300491 -0.302631  0.677131  \n","1 -0.373306 -0.851116  1.097206 -0.421438 -0.339957 -0.923106  \n","2 -0.761454 -0.550586 -2.955878  7.777107 -3.755432  1.145135  \n","3  0.057693 -0.470065  0.632124  0.005647  0.170056 -0.961741  \n","4  0.263432  1.161720 -0.911299  2.220866  1.635673  0.715806  \n","\n","[5 rows x 23 columns]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["X_train_raw_transform, X_test_raw_transform = robust_scaler(X_train_raw_transform, X_test_raw_transform)\n","X_train_raw_transform.head()"]},{"cell_type":"code","execution_count":19,"id":"586432ee","metadata":{},"outputs":[],"source":["X_test_final = X_test_raw_transform\n","y_test_final = y_test_raw"]},{"cell_type":"code","execution_count":20,"id":"e1a16a82","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of fraud transactions in test set:  149\n"]}],"source":["print(\"Number of fraud transactions in test set: \", sum(y_test_final))"]},{"cell_type":"markdown","id":"90b6f2ce","metadata":{},"source":["## Splitting cleaned data"]},{"cell_type":"code","execution_count":21,"id":"e80e9876","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Time</th>\n","      <th>V1</th>\n","      <th>V2</th>\n","      <th>V3</th>\n","      <th>V4</th>\n","      <th>V5</th>\n","      <th>V6</th>\n","      <th>V7</th>\n","      <th>V8</th>\n","      <th>V9</th>\n","      <th>...</th>\n","      <th>V21</th>\n","      <th>V22</th>\n","      <th>V23</th>\n","      <th>V24</th>\n","      <th>V25</th>\n","      <th>V26</th>\n","      <th>V27</th>\n","      <th>V28</th>\n","      <th>Amount</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>174270</th>\n","      <td>121845.0</td>\n","      <td>-0.687455</td>\n","      <td>0.034162</td>\n","      <td>1.674511</td>\n","      <td>0.486713</td>\n","      <td>-0.013900</td>\n","      <td>-0.223002</td>\n","      <td>0.423842</td>\n","      <td>-0.106400</td>\n","      <td>0.214356</td>\n","      <td>...</td>\n","      <td>0.087149</td>\n","      <td>0.249998</td>\n","      <td>0.179825</td>\n","      <td>-0.098846</td>\n","      <td>-0.479789</td>\n","      <td>0.328370</td>\n","      <td>-0.047519</td>\n","      <td>-0.028477</td>\n","      <td>129.00</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>235212</th>\n","      <td>148299.0</td>\n","      <td>2.085141</td>\n","      <td>0.107610</td>\n","      <td>-1.781910</td>\n","      <td>0.387274</td>\n","      <td>0.434617</td>\n","      <td>-0.806820</td>\n","      <td>0.139437</td>\n","      <td>-0.190544</td>\n","      <td>0.600858</td>\n","      <td>...</td>\n","      <td>-0.382071</td>\n","      <td>-1.025575</td>\n","      <td>0.327917</td>\n","      <td>0.361538</td>\n","      <td>-0.258820</td>\n","      <td>0.183453</td>\n","      <td>-0.067095</td>\n","      <td>-0.033363</td>\n","      <td>1.98</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>82595</th>\n","      <td>59467.0</td>\n","      <td>-2.882895</td>\n","      <td>-0.582806</td>\n","      <td>-0.041839</td>\n","      <td>1.727245</td>\n","      <td>-1.063354</td>\n","      <td>0.656207</td>\n","      <td>1.152295</td>\n","      <td>0.355095</td>\n","      <td>-0.149342</td>\n","      <td>...</td>\n","      <td>-0.257529</td>\n","      <td>0.107410</td>\n","      <td>-0.925797</td>\n","      <td>0.135460</td>\n","      <td>-0.195552</td>\n","      <td>-0.215286</td>\n","      <td>1.259925</td>\n","      <td>-0.480507</td>\n","      <td>437.55</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>106418</th>\n","      <td>69958.0</td>\n","      <td>1.191132</td>\n","      <td>0.405585</td>\n","      <td>0.440365</td>\n","      <td>0.707892</td>\n","      <td>-0.231695</td>\n","      <td>-0.759512</td>\n","      <td>0.100985</td>\n","      <td>-0.157308</td>\n","      <td>-0.183385</td>\n","      <td>...</td>\n","      <td>-0.224160</td>\n","      <td>-0.552896</td>\n","      <td>0.184056</td>\n","      <td>0.394377</td>\n","      <td>0.142250</td>\n","      <td>0.099725</td>\n","      <td>0.002033</td>\n","      <td>0.033406</td>\n","      <td>1.79</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>197956</th>\n","      <td>132254.0</td>\n","      <td>-0.546651</td>\n","      <td>-0.321071</td>\n","      <td>-0.492789</td>\n","      <td>-2.394851</td>\n","      <td>0.372501</td>\n","      <td>-0.680291</td>\n","      <td>0.826443</td>\n","      <td>-0.284000</td>\n","      <td>-0.825438</td>\n","      <td>...</td>\n","      <td>0.452065</td>\n","      <td>1.344924</td>\n","      <td>-0.293361</td>\n","      <td>-1.018657</td>\n","      <td>-0.231676</td>\n","      <td>-0.069155</td>\n","      <td>0.360589</td>\n","      <td>0.225280</td>\n","      <td>142.70</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 31 columns</p>\n","</div>"],"text/plain":["            Time        V1        V2        V3        V4        V5        V6  \\\n","174270  121845.0 -0.687455  0.034162  1.674511  0.486713 -0.013900 -0.223002   \n","235212  148299.0  2.085141  0.107610 -1.781910  0.387274  0.434617 -0.806820   \n","82595    59467.0 -2.882895 -0.582806 -0.041839  1.727245 -1.063354  0.656207   \n","106418   69958.0  1.191132  0.405585  0.440365  0.707892 -0.231695 -0.759512   \n","197956  132254.0 -0.546651 -0.321071 -0.492789 -2.394851  0.372501 -0.680291   \n","\n","              V7        V8        V9  ...       V21       V22       V23  \\\n","174270  0.423842 -0.106400  0.214356  ...  0.087149  0.249998  0.179825   \n","235212  0.139437 -0.190544  0.600858  ... -0.382071 -1.025575  0.327917   \n","82595   1.152295  0.355095 -0.149342  ... -0.257529  0.107410 -0.925797   \n","106418  0.100985 -0.157308 -0.183385  ... -0.224160 -0.552896  0.184056   \n","197956  0.826443 -0.284000 -0.825438  ...  0.452065  1.344924 -0.293361   \n","\n","             V24       V25       V26       V27       V28  Amount  Class  \n","174270 -0.098846 -0.479789  0.328370 -0.047519 -0.028477  129.00      0  \n","235212  0.361538 -0.258820  0.183453 -0.067095 -0.033363    1.98      0  \n","82595   0.135460 -0.195552 -0.215286  1.259925 -0.480507  437.55      0  \n","106418  0.394377  0.142250  0.099725  0.002033  0.033406    1.79      0  \n","197956 -1.018657 -0.231676 -0.069155  0.360589  0.225280  142.70      0  \n","\n","[5 rows x 31 columns]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["temp_df = pd.concat([X_train_raw, y_train_raw], axis=1)\n","temp_df.head()"]},{"cell_type":"code","execution_count":22,"id":"a97b7e95","metadata":{},"outputs":[],"source":["temp_df = eliminate_extreme_amount(temp_df)\n","y_train_cleaned = temp_df['Class']\n","X_train_cleaned = temp_df.drop(['Class'], axis=1)\n","\n","# transform & scale cleaned data\n","X_train_cleaned_transform = transformer.fit_transform(X_train_cleaned)\n","X_test_cleaned_transform = transformer.transform(deepcopy(X_test_raw))\n","# only care about the cleaned transform, ignore the raw it's just here to be a filler\n","X_train_cleaned_transform, X_test_cleaned_transform = robust_scaler(X_train_cleaned_transform, X_test_cleaned_transform)"]},{"cell_type":"code","execution_count":23,"id":"236e46b6","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of fraud transactions in cleaned training set:  343\n","No fraud transaction was dropped in the cleaning process\n"]}],"source":["print(\"Number of fraud transactions in cleaned training set: \", len(temp_df[temp_df.Class==1]))\n","if(len(temp_df[temp_df.Class==1]) + sum(y_test_final) == 492):\n","    print(\"No fraud transaction was dropped in the cleaning process\")"]},{"cell_type":"markdown","id":"d6eb8923","metadata":{},"source":["### Clean data of extreme values"]},{"cell_type":"code","execution_count":24,"id":"148676cb","metadata":{"id":"148676cb"},"outputs":[],"source":["# Outlier Removal\n","normal, extreme = outlier_removal(raw)"]},{"cell_type":"code","execution_count":25,"id":"6bbce5b9","metadata":{"id":"6bbce5b9"},"outputs":[],"source":["## only care about train_cleaned \n","X_train_cleaned, X_test_cleaned, y_train_cleaned, y_test_cleaned = \\\n","    stratified_train_test_byclass(normal, feature_names, [class_name, 'TimeHour'])\n"]},{"cell_type":"markdown","id":"a5e00952","metadata":{},"source":["Note that after transforming, Amount is replaced by lnAmount (though the name is still Amount).\n","\n","**Ignore all the test_cleaned because we won't be using it**"]},{"cell_type":"code","execution_count":26,"id":"3e184ed6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1689938575941,"user":{"displayName":"Linh Vu","userId":"10863104398479265021"},"user_tz":-420},"id":"3e184ed6","outputId":"d6a9fdaa-4a3a-41ff-9680-dcc79beace7c"},"outputs":[],"source":["transformer = Pipeline([('logAmount', log_transform),\n","                        ('dropFeatures', drop_feature)])\n","\n","X_train_cleaned_transform = transformer.fit_transform(X_train_cleaned)\n","X_test_cleaned_transform = transformer.transform(X_test_cleaned)"]},{"cell_type":"code","execution_count":27,"id":"49614e69","metadata":{"id":"49614e69"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>V1</th>\n","      <th>V2</th>\n","      <th>V3</th>\n","      <th>V4</th>\n","      <th>V5</th>\n","      <th>V6</th>\n","      <th>V7</th>\n","      <th>V8</th>\n","      <th>V9</th>\n","      <th>V10</th>\n","      <th>...</th>\n","      <th>V16</th>\n","      <th>V17</th>\n","      <th>V18</th>\n","      <th>V19</th>\n","      <th>V20</th>\n","      <th>V21</th>\n","      <th>V23</th>\n","      <th>V27</th>\n","      <th>V28</th>\n","      <th>Amount</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-1.114702</td>\n","      <td>1.244721</td>\n","      <td>-0.177658</td>\n","      <td>1.846758</td>\n","      <td>-1.744041</td>\n","      <td>1.811943</td>\n","      <td>1.454292</td>\n","      <td>1.886333</td>\n","      <td>-1.519418</td>\n","      <td>0.846510</td>\n","      <td>...</td>\n","      <td>0.111553</td>\n","      <td>0.509890</td>\n","      <td>0.367708</td>\n","      <td>0.659835</td>\n","      <td>0.824716</td>\n","      <td>0.588245</td>\n","      <td>1.375411</td>\n","      <td>3.332335</td>\n","      <td>0.389880</td>\n","      <td>1.203615</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.639810</td>\n","      <td>0.456739</td>\n","      <td>0.833529</td>\n","      <td>0.370218</td>\n","      <td>0.446726</td>\n","      <td>2.075312</td>\n","      <td>-0.364967</td>\n","      <td>-1.064472</td>\n","      <td>0.385250</td>\n","      <td>0.130319</td>\n","      <td>...</td>\n","      <td>-0.119658</td>\n","      <td>-0.477648</td>\n","      <td>0.779824</td>\n","      <td>1.186811</td>\n","      <td>-0.215427</td>\n","      <td>2.056431</td>\n","      <td>-0.504207</td>\n","      <td>0.970231</td>\n","      <td>-0.721151</td>\n","      <td>-0.276364</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.721758</td>\n","      <td>0.615381</td>\n","      <td>0.655969</td>\n","      <td>-0.152278</td>\n","      <td>0.545277</td>\n","      <td>0.640686</td>\n","      <td>0.795807</td>\n","      <td>-0.281519</td>\n","      <td>-0.046333</td>\n","      <td>0.109694</td>\n","      <td>...</td>\n","      <td>-0.154166</td>\n","      <td>-0.669840</td>\n","      <td>0.186398</td>\n","      <td>1.166049</td>\n","      <td>0.992440</td>\n","      <td>-0.510002</td>\n","      <td>-0.900649</td>\n","      <td>0.207575</td>\n","      <td>-0.782788</td>\n","      <td>0.147851</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.524241</td>\n","      <td>0.348256</td>\n","      <td>-1.595526</td>\n","      <td>0.220600</td>\n","      <td>0.999321</td>\n","      <td>-1.073199</td>\n","      <td>0.761802</td>\n","      <td>-1.288445</td>\n","      <td>-0.132851</td>\n","      <td>-0.270678</td>\n","      <td>...</td>\n","      <td>0.011246</td>\n","      <td>0.787491</td>\n","      <td>-0.155088</td>\n","      <td>-0.227657</td>\n","      <td>0.009036</td>\n","      <td>0.108273</td>\n","      <td>0.102523</td>\n","      <td>-0.756465</td>\n","      <td>-0.509318</td>\n","      <td>-0.201153</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.108411</td>\n","      <td>-0.257039</td>\n","      <td>0.024173</td>\n","      <td>-0.117818</td>\n","      <td>-0.156087</td>\n","      <td>0.520431</td>\n","      <td>-0.432375</td>\n","      <td>0.173755</td>\n","      <td>0.490834</td>\n","      <td>-0.141257</td>\n","      <td>...</td>\n","      <td>0.548119</td>\n","      <td>-0.508849</td>\n","      <td>-0.433402</td>\n","      <td>-0.096612</td>\n","      <td>0.343403</td>\n","      <td>-0.359064</td>\n","      <td>0.061518</td>\n","      <td>-0.412397</td>\n","      <td>-0.012714</td>\n","      <td>0.363456</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 23 columns</p>\n","</div>"],"text/plain":["         V1        V2        V3        V4        V5        V6        V7  \\\n","0 -1.114702  1.244721 -0.177658  1.846758 -1.744041  1.811943  1.454292   \n","1 -0.639810  0.456739  0.833529  0.370218  0.446726  2.075312 -0.364967   \n","2 -0.721758  0.615381  0.655969 -0.152278  0.545277  0.640686  0.795807   \n","3  0.524241  0.348256 -1.595526  0.220600  0.999321 -1.073199  0.761802   \n","4  0.108411 -0.257039  0.024173 -0.117818 -0.156087  0.520431 -0.432375   \n","\n","         V8        V9       V10  ...       V16       V17       V18       V19  \\\n","0  1.886333 -1.519418  0.846510  ...  0.111553  0.509890  0.367708  0.659835   \n","1 -1.064472  0.385250  0.130319  ... -0.119658 -0.477648  0.779824  1.186811   \n","2 -0.281519 -0.046333  0.109694  ... -0.154166 -0.669840  0.186398  1.166049   \n","3 -1.288445 -0.132851 -0.270678  ...  0.011246  0.787491 -0.155088 -0.227657   \n","4  0.173755  0.490834 -0.141257  ...  0.548119 -0.508849 -0.433402 -0.096612   \n","\n","        V20       V21       V23       V27       V28    Amount  \n","0  0.824716  0.588245  1.375411  3.332335  0.389880  1.203615  \n","1 -0.215427  2.056431 -0.504207  0.970231 -0.721151 -0.276364  \n","2  0.992440 -0.510002 -0.900649  0.207575 -0.782788  0.147851  \n","3  0.009036  0.108273  0.102523 -0.756465 -0.509318 -0.201153  \n","4  0.343403 -0.359064  0.061518 -0.412397 -0.012714  0.363456  \n","\n","[5 rows x 23 columns]"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["X_train_cleaned_transform, X_test_cleaned_transform = \\\n","    robust_scaler(X_train_cleaned_transform, X_test_cleaned_transform)\n","X_train_cleaned_transform.head()"]},{"cell_type":"markdown","id":"d6057764","metadata":{},"source":["# Validate models"]},{"cell_type":"markdown","id":"bfc3da13","metadata":{},"source":["## Logistic Regression"]},{"cell_type":"markdown","id":"05a91a44","metadata":{},"source":["### Summary of the plan"]},{"cell_type":"markdown","id":"ed64a6a6","metadata":{},"source":["1. Split raw into train_raw & test_raw\n","2. Set test_raw to be final_test \n","3. Remove extreme_values from train_raw to make train_cleaned \n","4. Fit model on train_raw & train_cleaned\n","5. Test both model on final_test "]},{"cell_type":"markdown","id":"a632c209","metadata":{},"source":["### Model assumptions"]},{"cell_type":"markdown","id":"e4d88aa4","metadata":{},"source":["- LogReg assumes the dependent variable is binary, as is the case of this problem where we have 2 labels: 0 (Genuine) and 1 (Fraud). \n","- LogReg assumes data is linear separable. As we have no idea how to verify this (it is part of the truth of the data), we ignore this ^^ \n","- LogReg assumes no highly influential outlier data. Thus, we shall clean the data set of extreme values to enhance model's performance. "]},{"cell_type":"markdown","id":"ce2c63c2","metadata":{},"source":["### LogReg on raw data (imbalanced)"]},{"cell_type":"code","execution_count":28,"id":"de41c655","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold 0:\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_34643/43376374.py:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data.Amount = np.log(data.Amount + epsilon)\n"]},{"name":"stdout","output_type":"stream","text":["LOGISTIC REGRESSION ON RAW DATA RESULTS\n","test set confusion matrix:\n"," [[39801     4]\n"," [   23    45]]\n","recall score:  0.6617647058823529\n","precision score:  0.9183673469387755\n","accuracy score:  0.9993228500489053\n","f1 score:  0.7692307692307692\n","ROC AUC: 0.9459353318013551\n","Fold 1:\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_34643/43376374.py:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data.Amount = np.log(data.Amount + epsilon)\n"]},{"name":"stdout","output_type":"stream","text":["LOGISTIC REGRESSION ON RAW DATA RESULTS\n","test set confusion matrix:\n"," [[39800     4]\n"," [   27    42]]\n","recall score:  0.6086956521739131\n","precision score:  0.9130434782608695\n","accuracy score:  0.999222531537632\n","f1 score:  0.7304347826086955\n","ROC AUC: 0.9870892736728811\n","Fold 2:\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_34643/43376374.py:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data.Amount = np.log(data.Amount + epsilon)\n"]},{"name":"stdout","output_type":"stream","text":["LOGISTIC REGRESSION ON RAW DATA RESULTS\n","test set confusion matrix:\n"," [[39799     5]\n"," [   37    32]]\n","recall score:  0.463768115942029\n","precision score:  0.8648648648648649\n","accuracy score:  0.9989466556316304\n","f1 score:  0.6037735849056604\n","ROC AUC: 0.9323576830818838\n","Fold 3:\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_34643/43376374.py:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data.Amount = np.log(data.Amount + epsilon)\n"]},{"name":"stdout","output_type":"stream","text":["LOGISTIC REGRESSION ON RAW DATA RESULTS\n","test set confusion matrix:\n"," [[39799     5]\n"," [   34    35]]\n","recall score:  0.5072463768115942\n","precision score:  0.875\n","accuracy score:  0.9990218945150854\n","f1 score:  0.6422018348623854\n","ROC AUC: 0.9739291368284304\n","Fold 4:\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_34643/43376374.py:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data.Amount = np.log(data.Amount + epsilon)\n"]},{"name":"stdout","output_type":"stream","text":["LOGISTIC REGRESSION ON RAW DATA RESULTS\n","test set confusion matrix:\n"," [[39799     5]\n"," [   31    37]]\n","recall score:  0.5441176470588235\n","precision score:  0.8809523809523809\n","accuracy score:  0.9990971107544141\n","f1 score:  0.6727272727272727\n","ROC AUC: 0.9855350038719135\n","------------------------------------\n","MODEL VALIDATION: LOGISTIC REGRESSION ON RAW DATA RESULTS\n","Number of folds: 5\n","Avg precision score:  0.8904456142033782\n","Avg recall score:  0.5571184995737426\n"]}],"source":["cv1 = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n","cv1.get_n_splits(X_train_raw, y_train_raw)\n","precision_LR_raw = []\n","recall_LR_raw = []\n","for i, (train_index, test_index) in enumerate(cv1.split(X_train_raw, y_train_raw)):\n","    print(f\"Fold {i}:\")\n","\n","    ## train_split and test_split will be train and test for the fold i\n","    ## Both train_split and test_split are raw.\n","    X_train_fold = X_train_raw.iloc[train_index]\n","    X_test_fold = X_train_raw.iloc[test_index]\n","    y_train_fold = y_train_raw.iloc[train_index]\n","    y_test_fold = y_train_raw.iloc[test_index]\n","\n","    # transform & rescale train & test set \n","    X_train_fold_transform = transformer.fit_transform(X_train_fold)\n","    X_test_fold_transform = transformer.transform(deepcopy(X_test_fold))\n","    X_train_fold_transform, X_test_fold_transform = \\\n","        robust_scaler(X_train_fold_transform, X_test_fold_transform)\n","    \n","    # fit model \n","    y_raw_LR, y_raw_LR_proba = get_predictions(LogisticRegression(C=0.01, penalty='l1', solver='liblinear'),\n","                                           X_train_fold_transform, y_train_fold, X_test_fold_transform)\n","\n","    print('LOGISTIC REGRESSION ON RAW DATA RESULTS')\n","    fold_precision, fold_recall = print_scores(y_test_fold, y_raw_LR, y_raw_LR_proba)\n","    precision_LR_raw.append(fold_precision)\n","    recall_LR_raw.append(fold_recall)\n","\n","print('------------------------------------')\n","print('MODEL VALIDATION: LOGISTIC REGRESSION ON RAW DATA RESULTS')\n","print('Number of folds: 5')\n","print(\"Avg precision score: \", np.array(precision_LR_raw).mean())\n","print(\"Avg recall score: \", np.array(recall_LR_raw).mean())"]},{"cell_type":"markdown","id":"a536debf","metadata":{},"source":["### LogReg on cleaned data (imbalanced)"]},{"cell_type":"code","execution_count":29,"id":"37cabe52","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold 0:\n","LOGISTIC REGRESSION ON CLEANED DATA RESULTS\n","test set confusion matrix:\n"," [[39792    13]\n"," [   15    53]]\n","recall score:  0.7794117647058824\n","precision score:  0.803030303030303\n","accuracy score:  0.9992977704210869\n","f1 score:  0.7910447761194029\n","ROC AUC: 0.9531007780577374\n","Fold 1:\n","LOGISTIC REGRESSION ON CLEANED DATA RESULTS\n","test set confusion matrix:\n"," [[39790    14]\n"," [   18    51]]\n","recall score:  0.7391304347826086\n","precision score:  0.7846153846153846\n","accuracy score:  0.9991974519098137\n","f1 score:  0.7611940298507462\n","ROC AUC: 0.9854446206702698\n","Fold 2:\n","LOGISTIC REGRESSION ON CLEANED DATA RESULTS\n","test set confusion matrix:\n"," [[39793    11]\n"," [   25    44]]\n","recall score:  0.6376811594202898\n","precision score:  0.8\n","accuracy score:  0.9990971333985403\n","f1 score:  0.7096774193548386\n","ROC AUC: 0.9394103571267325\n","Fold 3:\n","LOGISTIC REGRESSION ON CLEANED DATA RESULTS\n","test set confusion matrix:\n"," [[39793    11]\n"," [   22    47]]\n","recall score:  0.6811594202898551\n","precision score:  0.8103448275862069\n","accuracy score:  0.9991723722819953\n","f1 score:  0.7401574803149606\n","ROC AUC: 0.9783795671252908\n","Fold 4:\n","LOGISTIC REGRESSION ON CLEANED DATA RESULTS\n","test set confusion matrix:\n"," [[39794    10]\n"," [   19    49]]\n","recall score:  0.7205882352941176\n","precision score:  0.8305084745762712\n","accuracy score:  0.9992726725521669\n","f1 score:  0.7716535433070865\n","ROC AUC: 0.9899740345339221\n","------------------------------------\n","MODEL VALIDATION: LOGISTIC REGRESSION ON CLEANED DATA RESULTS\n","Number of folds: 5\n","Avg precision score:  0.8056997979616332\n","Avg recall score:  0.7115942028985507\n"]}],"source":["cv2 = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n","cv2.get_n_splits(X_train_raw, y_train_raw)\n","precision_LR_cleaned = [] \n","recall_LR_cleaned = [] \n","for i, (train_index, test_index) in enumerate(cv2.split(X_train_raw, y_train_raw)):\n","    print(f\"Fold {i}:\")\n","\n","    ## train_split and test_split will be train and test for the fold i\n","    ## Both train_split and test_split are raw.\n","    X_train_fold = X_train_raw.iloc[train_index]\n","    X_test_fold = X_train_raw.iloc[test_index]\n","    y_train_fold = y_train_raw.iloc[train_index]\n","    y_test_fold = y_train_raw.iloc[test_index]\n","\n","    # clean (remove outlier) training set only \n","    temp = pd.concat([X_train_fold, y_train_fold], axis=1)\n","    temp, extr = outlier_removal(temp)\n","    y_train_fold_cleaned = temp['Class']\n","    X_train_fold_cleaned = temp.drop(['Class'], axis=1)\n","\n","    # transform & rescale test & train set \n","    X_train_fold_transform = transformer.fit_transform(X_train_fold_cleaned)\n","    X_test_fold_transform = transformer.transform(deepcopy(X_test_fold))\n","    X_train_fold_transform, X_test_fold_transform = \\\n","        robust_scaler(X_train_fold_transform, X_test_fold_transform)\n","    \n","    # fit model\n","    y_cleaned_LR, y_cleaned_LR_proba = get_predictions(LogisticRegression(C=0.01, penalty='l1', solver='liblinear'),\n","                                           X_train_fold_transform, y_train_fold_cleaned, X_test_fold_transform)\n","\n","    print('LOGISTIC REGRESSION ON CLEANED DATA RESULTS')\n","    fold_precision, fold_recall = print_scores(y_test_fold, y_cleaned_LR, y_cleaned_LR_proba)\n","    precision_LR_cleaned.append(fold_precision)\n","    recall_LR_cleaned.append(fold_recall)\n","\n","print('------------------------------------')\n","print('MODEL VALIDATION: LOGISTIC REGRESSION ON CLEANED DATA RESULTS')\n","print('Number of folds: 5')\n","print(\"Avg precision score: \", np.array(precision_LR_cleaned).mean())\n","print(\"Avg recall score: \", np.array(recall_LR_cleaned).mean())"]},{"cell_type":"markdown","id":"a9fbfe8e","metadata":{},"source":["### LogReg on undersampled raw data (balanced)"]},{"cell_type":"code","execution_count":33,"id":"055fca8c","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold 0:\n","Undersampled data is balanced between classes.\n","LOGISTIC REGRESSION ON UNDERSAMPLED RAW DATA RESULTS\n","test set confusion matrix:\n"," [[19371 20434]\n"," [    5    63]]\n","recall score:  0.9264705882352942\n","precision score:  0.003073620529833634\n","accuracy score:  0.4873974870212926\n","f1 score:  0.006126914660831509\n","ROC AUC: 0.9277185839792519\n","Fold 1:\n","Undersampled data is balanced between classes.\n","LOGISTIC REGRESSION ON UNDERSAMPLED RAW DATA RESULTS\n","test set confusion matrix:\n"," [[19755 20049]\n"," [    8    61]]\n","recall score:  0.8840579710144928\n","precision score:  0.0030333167578319243\n","accuracy score:  0.49697790484789206\n","f1 score:  0.00604588929084692\n","ROC AUC: 0.8780386211275832\n","Fold 2:\n","Undersampled data is balanced between classes.\n","LOGISTIC REGRESSION ON UNDERSAMPLED RAW DATA RESULTS\n","test set confusion matrix:\n"," [[19922 19882]\n"," [   15    54]]\n","recall score:  0.782608695652174\n","precision score:  0.002708667736757624\n","accuracy score:  0.5009906452988238\n","f1 score:  0.005398650337415646\n","ROC AUC: 0.777392556861957\n","Fold 3:\n","Undersampled data is balanced between classes.\n","LOGISTIC REGRESSION ON UNDERSAMPLED RAW DATA RESULTS\n","test set confusion matrix:\n"," [[19363 20441]\n"," [    9    60]]\n","recall score:  0.8695652173913043\n","precision score:  0.00292668650309741\n","accuracy score:  0.48712161111529106\n","f1 score:  0.005833738454059309\n","ROC AUC: 0.8479833794287661\n","Fold 4:\n","Undersampled data is balanced between classes.\n","LOGISTIC REGRESSION ON UNDERSAMPLED RAW DATA RESULTS\n","test set confusion matrix:\n"," [[19765 20039]\n"," [    8    60]]\n","recall score:  0.8823529411764706\n","precision score:  0.002985223145430121\n","accuracy score:  0.4972160914927769\n","f1 score:  0.005950314870828582\n","ROC AUC: 0.8757832496881779\n","------------------------------------\n","MODEL VALIDATION: LOGISTIC REGRESSION ON BALANCED UNDERSAMPLED RAW DATA RESULTS\n","Number of folds: 5\n","Avg precision score:  0.002945502934590143\n","Avg recall score:  0.869011082693947\n"]}],"source":["cv3 = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n","cv3.get_n_splits(X_train_raw, y_train_raw)\n","precision_LR_und = []\n","recall_LR_und = [] \n","for i, (train_index, test_index) in enumerate(cv3.split(X_train_raw, y_train_raw)):\n","    print(f\"Fold {i}:\")\n","\n","    ## train_split and test_split will be train and test for the fold i\n","    ## Both train_split and test_split are raw.\n","    X_train_fold = X_train_raw.iloc[train_index]\n","    X_test_fold = X_train_raw.iloc[test_index]\n","    y_train_fold = y_train_raw.iloc[train_index]\n","    y_test_fold = y_train_raw.iloc[test_index]\n","\n","    # undersample the train set \n","    tmp = pd.concat([X_train_fold, y_train_fold], axis=1)\n","    fraud_index = np.array(tmp[tmp.Class==1].index)\n","    n_fraud = len(fraud_index)\n","\n","    genuine_index = np.array(tmp[tmp.Class==0].index)\n","    rus_genuine_index = np.array(np.random.choice(a=genuine_index, size=n_fraud, replace=False))\n","    rus_index = np.concatenate([rus_genuine_index, fraud_index])\n","    undersampled_df = tmp.loc[rus_index]\n","\n","    if(len(undersampled_df[undersampled_df.Class==0]) == len(undersampled_df[undersampled_df.Class==1])):\n","        print(\"Undersampled data is balanced between classes.\")\n","\n","    y_train_fold_und = undersampled_df['Class'].values \n","    X_train_fold_und = undersampled_df.drop(['Class'], axis=1)\n","\n","    # transform & rescale train and test \n","    X_train_fold_transform = transformer.fit_transform(X_train_fold_und)\n","    X_test_fold_transform = transformer.transform(deepcopy(X_test_fold))\n","    X_train_fold_transform, X_test_fold_transform = \\\n","        robust_scaler(X_train_fold_transform, X_test_fold_transform)\n","    \n","    # fit model\n","    y_und_LR, y_und_LR_proba = get_predictions(LogisticRegression(C=0.01, penalty='l1', solver='liblinear'),\n","                                           X_train_fold_transform, y_train_fold_und, X_test_fold_transform)\n","\n","    print('LOGISTIC REGRESSION ON UNDERSAMPLED RAW DATA RESULTS')\n","    fold_precision, fold_recall = print_scores(y_test_fold, y_und_LR, y_und_LR_proba)\n","    precision_LR_und.append(fold_precision)\n","    recall_LR_und.append(fold_recall)\n","\n","print('------------------------------------')\n","print('MODEL VALIDATION: LOGISTIC REGRESSION ON BALANCED UNDERSAMPLED RAW DATA RESULTS')\n","print('Number of folds: 5')\n","print(\"Avg precision score: \", np.array(precision_LR_und).mean())\n","print(\"Avg recall score: \", np.array(recall_LR_und).mean())"]},{"cell_type":"markdown","id":"f69cf32c","metadata":{},"source":["**Comment 1:** LogReg performs much better after extreme values have been removed from each features. \n","**Comment 2:** On RAW data\n","- Undersampling Class 0 to have the same number of observations as Class 1 makes LogReg has low precision (0.003) and high recall (0.85).\n","- Not undersampling Class 0 makes LogReg has high precision (0.89) and low recall (0.557)\n","\n","--> Suspect: Undersample Class 0 but makes the size of Class 0 still bigger than Class 1 helps us achieve the best precision and recall? \n","\n","Let's tune this parameter to testify the idea."]},{"cell_type":"markdown","id":"b3749e45","metadata":{},"source":["### LogReg on Semi-Undersampled Raw Data"]},{"cell_type":"markdown","id":"cb924696","metadata":{},"source":["**Define the function**"]},{"cell_type":"code","execution_count":27,"id":"c3ea3596","metadata":{},"outputs":[],"source":["def SemiUnderSampling_LR(k, showFoldResult=True, X_train_raw=X_train_raw, y_train_raw=y_train_raw):  \n","    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n","    cv.get_n_splits(X_train_raw, y_train_raw)\n","    precision_LR_semi = []\n","    recall_LR_semi = [] \n","    for i, (train_index, test_index) in enumerate(cv.split(X_train_raw, y_train_raw)):\n","\n","        ## train_split and test_split will be train and test for the fold i\n","        ## Both train_split and test_split are raw.\n","        X_train_fold = X_train_raw.iloc[train_index]\n","        X_test_fold = X_train_raw.iloc[test_index]\n","        y_train_fold = y_train_raw.iloc[train_index]\n","        y_test_fold = y_train_raw.iloc[test_index]\n","\n","        # undersample the train set \n","        tmp = pd.concat([X_train_fold, y_train_fold], axis=1)\n","        fraud_index = np.array(tmp[tmp.Class==1].index)\n","        n_fraud = len(fraud_index)\n","\n","        genuine_index = np.array(tmp[tmp.Class==0].index)\n","        ### size=k*n_fraud, we tune this k value to find the best\n","        rus_genuine_index = np.array(np.random.choice(a=genuine_index, size=k*n_fraud, replace=False))\n","        rus_index = np.concatenate([rus_genuine_index, fraud_index])\n","        undersampled_df = tmp.loc[rus_index]\n","\n","        y_train_fold_semi = undersampled_df['Class'].values \n","        X_train_fold_semi = undersampled_df.drop(['Class'], axis=1)\n","\n","        # transform & rescale train and test \n","        X_train_fold_transform = transformer.fit_transform(X_train_fold_semi)\n","        X_test_fold_transform = transformer.transform(deepcopy(X_test_fold))\n","        X_train_fold_transform, X_test_fold_transform = \\\n","            robust_scaler(X_train_fold_transform, X_test_fold_transform)\n","        \n","        # fit model\n","        y_semi_LR, y_semi_LR_proba = get_predictions(LogisticRegression(C=0.01, penalty='l1', solver='liblinear'),\n","                                            X_train_fold_transform, y_train_fold_semi, X_test_fold_transform)\n","\n","        fold_precision = 0\n","        fold_recall = 0 \n","\n","        if (showFoldResult==True):\n","            print(f\"Fold {i}:\")\n","            print('LOGISTIC REGRESSION ON UNDERSAMPLED RAW DATA RESULTS')\n","            fold_precision, fold_recall = print_scores(y_test_fold, y_semi_LR, y_semi_LR_proba)\n","        else: \n","            fold_precision = precision_score(y_test_fold, y_semi_LR)\n","            fold_recall = recall_score(y_test_fold, y_semi_LR)\n","\n","        precision_LR_semi.append(fold_precision)\n","        recall_LR_semi.append(fold_recall)\n","\n","    avg_precision = np.array(precision_LR_semi).mean()\n","    avg_recall = np.array(recall_LR_semi).mean()\n","    print('------------------------------------')\n","    print(f\"Class 0 size is {k} times Class 1 size.\")\n","    print(\"Avg precision score: \", avg_precision)\n","    print(\"Avg recall score: \", avg_recall)\n","    \n","    return avg_precision, avg_recall"]},{"cell_type":"markdown","id":"9d114104","metadata":{},"source":["**Tune parameter k**"]},{"cell_type":"code","execution_count":28,"id":"4737ac31","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["------------------------------------\n","Class 0 size is 10 times Class 1 size.\n","Avg precision score:  0.6801499514253768\n","Avg recall score:  0.8134697357203751\n"]}],"source":["pre10, rec10 = SemiUnderSampling_LR(k=10, showFoldResult=False)"]},{"cell_type":"code","execution_count":29,"id":"a1d720f8","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["------------------------------------\n","Class 0 size is 30 times Class 1 size.\n","Avg precision score:  0.8030169359427146\n","Avg recall score:  0.78154305200341\n"]}],"source":["prec30, rec30 = SemiUnderSampling_LR(k=30, showFoldResult=False)"]},{"cell_type":"code","execution_count":30,"id":"b6ec492c","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["------------------------------------\n","Class 0 size is 100 times Class 1 size.\n","Avg precision score:  0.8715817130651222\n","Avg recall score:  0.6910912190963342\n"]}],"source":["prec100, rec100 = SemiUnderSampling_LR(k=100, showFoldResult=False)"]},{"cell_type":"code","execution_count":51,"id":"8507948f","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["------------------------------------\n","Class 0 size is 1 times Class 1 size.\n","Avg precision score:  0.00292961791557932\n","Avg recall score:  0.8661125319693095\n","------------------------------------\n","Class 0 size is 2 times Class 1 size.\n","Avg precision score:  0.07499715581016743\n","Avg recall score:  0.8281756180733162\n","------------------------------------\n","Class 0 size is 3 times Class 1 size.\n","Avg precision score:  0.05680263837506559\n","Avg recall score:  0.8718243819266837\n","------------------------------------\n","Class 0 size is 4 times Class 1 size.\n","Avg precision score:  0.12589911789238553\n","Avg recall score:  0.8601449275362318\n","------------------------------------\n","Class 0 size is 5 times Class 1 size.\n","Avg precision score:  0.2240856269048647\n","Avg recall score:  0.8513640238704177\n","------------------------------------\n","Class 0 size is 6 times Class 1 size.\n","Avg precision score:  0.36875510946589724\n","Avg recall score:  0.8396419437340154\n","------------------------------------\n","Class 0 size is 7 times Class 1 size.\n","Avg precision score:  0.4757366442276366\n","Avg recall score:  0.8367433930093776\n","------------------------------------\n","Class 0 size is 8 times Class 1 size.\n","Avg precision score:  0.5700244888669935\n","Avg recall score:  0.83384484228474\n","------------------------------------\n","Class 0 size is 9 times Class 1 size.\n","Avg precision score:  0.6616854309231804\n","Avg recall score:  0.8163682864450127\n","------------------------------------\n","Class 0 size is 10 times Class 1 size.\n","Avg precision score:  0.6392899160825627\n","Avg recall score:  0.8192668371696504\n","------------------------------------\n","Class 0 size is 11 times Class 1 size.\n","Avg precision score:  0.6867266655547863\n","Avg recall score:  0.8134697357203751\n","------------------------------------\n","Class 0 size is 12 times Class 1 size.\n","Avg precision score:  0.7015796895847055\n","Avg recall score:  0.8076726342710996\n","------------------------------------\n","Class 0 size is 13 times Class 1 size.\n","Avg precision score:  0.7533674803836095\n","Avg recall score:  0.8047740835464621\n","------------------------------------\n","Class 0 size is 14 times Class 1 size.\n","Avg precision score:  0.7328592082323426\n","Avg recall score:  0.8076726342710998\n","------------------------------------\n","Class 0 size is 15 times Class 1 size.\n","Avg precision score:  0.7530351019916237\n","Avg recall score:  0.8076726342710998\n","------------------------------------\n","Class 0 size is 16 times Class 1 size.\n","Avg precision score:  0.7840635666722623\n","Avg recall score:  0.8076726342710998\n","------------------------------------\n","Class 0 size is 17 times Class 1 size.\n","Avg precision score:  0.7809856915739269\n","Avg recall score:  0.8076726342710998\n","------------------------------------\n","Class 0 size is 18 times Class 1 size.\n","Avg precision score:  0.7826183275221051\n","Avg recall score:  0.8018755328218244\n","------------------------------------\n","Class 0 size is 19 times Class 1 size.\n","Avg precision score:  0.7920530231291878\n","Avg recall score:  0.7960784313725491\n","------------------------------------\n","Class 0 size is 20 times Class 1 size.\n","Avg precision score:  0.7982649572649573\n","Avg recall score:  0.7989769820971867\n","------------------------------------\n","Class 0 size is 21 times Class 1 size.\n","Avg precision score:  0.8007312910829227\n","Avg recall score:  0.7931798806479113\n","------------------------------------\n","Class 0 size is 22 times Class 1 size.\n","Avg precision score:  0.7957553840652434\n","Avg recall score:  0.7989769820971867\n","------------------------------------\n","Class 0 size is 23 times Class 1 size.\n","Avg precision score:  0.8116907205737791\n","Avg recall score:  0.7902813299232736\n","------------------------------------\n","Class 0 size is 24 times Class 1 size.\n","Avg precision score:  0.7969948454900271\n","Avg recall score:  0.7844416027280477\n","------------------------------------\n","Class 0 size is 25 times Class 1 size.\n","Avg precision score:  0.8025312711234539\n","Avg recall score:  0.7786445012787724\n","------------------------------------\n","Class 0 size is 26 times Class 1 size.\n","Avg precision score:  0.8045873167312447\n","Avg recall score:  0.7786445012787724\n","------------------------------------\n","Class 0 size is 27 times Class 1 size.\n","Avg precision score:  0.8052542382724596\n","Avg recall score:  0.7902387041773231\n","------------------------------------\n","Class 0 size is 28 times Class 1 size.\n","Avg precision score:  0.8073140609191874\n","Avg recall score:  0.7902387041773231\n","------------------------------------\n","Class 0 size is 29 times Class 1 size.\n","Avg precision score:  0.8071795748252633\n","Avg recall score:  0.7786018755328218\n","------------------------------------\n","Class 0 size is 30 times Class 1 size.\n","Avg precision score:  0.8083295389915319\n","Avg recall score:  0.7844416027280477\n","------------------------------------\n","Class 0 size is 31 times Class 1 size.\n","Avg precision score:  0.8106776556776556\n","Avg recall score:  0.7960784313725491\n","------------------------------------\n","Class 0 size is 32 times Class 1 size.\n","Avg precision score:  0.8105530751107961\n","Avg recall score:  0.78154305200341\n","------------------------------------\n","Class 0 size is 33 times Class 1 size.\n","Avg precision score:  0.803598776795981\n","Avg recall score:  0.7844416027280477\n","------------------------------------\n","Class 0 size is 34 times Class 1 size.\n","Avg precision score:  0.8089697008000151\n","Avg recall score:  0.7639812446717817\n","------------------------------------\n","Class 0 size is 35 times Class 1 size.\n","Avg precision score:  0.8070716042538955\n","Avg recall score:  0.7669650468883205\n","------------------------------------\n","Class 0 size is 36 times Class 1 size.\n","Avg precision score:  0.8080328111785912\n","Avg recall score:  0.7699488491048593\n","------------------------------------\n","Class 0 size is 37 times Class 1 size.\n","Avg precision score:  0.8078224737148016\n","Avg recall score:  0.7815004262574595\n","------------------------------------\n","Class 0 size is 38 times Class 1 size.\n","Avg precision score:  0.8071083119490072\n","Avg recall score:  0.7786445012787724\n","------------------------------------\n","Class 0 size is 39 times Class 1 size.\n","Avg precision score:  0.8078481862964623\n","Avg recall score:  0.7581841432225064\n","------------------------------------\n","Class 0 size is 40 times Class 1 size.\n","Avg precision score:  0.8092133229089751\n","Avg recall score:  0.7670502983802215\n","------------------------------------\n","Class 0 size is 41 times Class 1 size.\n","Avg precision score:  0.8002939107347729\n","Avg recall score:  0.7465899403239555\n","------------------------------------\n","Class 0 size is 42 times Class 1 size.\n","Avg precision score:  0.8090912666120467\n","Avg recall score:  0.7525149190110827\n","------------------------------------\n","Class 0 size is 43 times Class 1 size.\n","Avg precision score:  0.8041593201574544\n","Avg recall score:  0.7407928388746803\n","------------------------------------\n","Class 0 size is 44 times Class 1 size.\n","Avg precision score:  0.8076085058209166\n","Avg recall score:  0.7699062233589087\n","------------------------------------\n","Class 0 size is 45 times Class 1 size.\n","Avg precision score:  0.8074101913204237\n","Avg recall score:  0.758312020460358\n","------------------------------------\n","Class 0 size is 46 times Class 1 size.\n","Avg precision score:  0.8032449887069453\n","Avg recall score:  0.7612105711849957\n","------------------------------------\n","Class 0 size is 47 times Class 1 size.\n","Avg precision score:  0.8063856492758845\n","Avg recall score:  0.7438618925831201\n","------------------------------------\n","Class 0 size is 48 times Class 1 size.\n","Avg precision score:  0.8093863982686603\n","Avg recall score:  0.7523017902813299\n","------------------------------------\n","Class 0 size is 49 times Class 1 size.\n","Avg precision score:  0.8111111267764495\n","Avg recall score:  0.7378942881500425\n","------------------------------------\n","Class 0 size is 50 times Class 1 size.\n","Avg precision score:  0.809788172299309\n","Avg recall score:  0.7467178175618072\n","------------------------------------\n","Class 0 size is 51 times Class 1 size.\n","Avg precision score:  0.8056785243741764\n","Avg recall score:  0.7378516624040921\n","------------------------------------\n","Class 0 size is 52 times Class 1 size.\n","Avg precision score:  0.8162247631400857\n","Avg recall score:  0.7378942881500425\n","------------------------------------\n","Class 0 size is 53 times Class 1 size.\n","Avg precision score:  0.8261630600452514\n","Avg recall score:  0.7552429667519182\n","------------------------------------\n","Class 0 size is 54 times Class 1 size.\n","Avg precision score:  0.8006686508804949\n","Avg recall score:  0.723231031543052\n","------------------------------------\n","Class 0 size is 55 times Class 1 size.\n","Avg precision score:  0.8053088004972068\n","Avg recall score:  0.7350383631713555\n","------------------------------------\n","Class 0 size is 56 times Class 1 size.\n","Avg precision score:  0.808689124027954\n","Avg recall score:  0.7261722080136402\n","------------------------------------\n","Class 0 size is 57 times Class 1 size.\n","Avg precision score:  0.8238742231973326\n","Avg recall score:  0.7349531116794543\n","------------------------------------\n","Class 0 size is 58 times Class 1 size.\n","Avg precision score:  0.8152812376385686\n","Avg recall score:  0.7582693947144075\n","------------------------------------\n","Class 0 size is 59 times Class 1 size.\n","Avg precision score:  0.8185526005325782\n","Avg recall score:  0.7319693094629156\n","------------------------------------\n","Class 0 size is 60 times Class 1 size.\n","Avg precision score:  0.8327752125699792\n","Avg recall score:  0.7233162830349531\n","------------------------------------\n","Class 0 size is 61 times Class 1 size.\n","Avg precision score:  0.8200460403881085\n","Avg recall score:  0.7378090366581416\n","------------------------------------\n","Class 0 size is 62 times Class 1 size.\n","Avg precision score:  0.8282329739226292\n","Avg recall score:  0.7232736572890025\n","------------------------------------\n","Class 0 size is 63 times Class 1 size.\n","Avg precision score:  0.8183306277056278\n","Avg recall score:  0.7320971867007672\n","------------------------------------\n","Class 0 size is 64 times Class 1 size.\n","Avg precision score:  0.8360445174238278\n","Avg recall score:  0.7261295822676896\n","------------------------------------\n","Class 0 size is 65 times Class 1 size.\n","Avg precision score:  0.8158860860206592\n","Avg recall score:  0.7349957374254049\n","------------------------------------\n","Class 0 size is 66 times Class 1 size.\n","Avg precision score:  0.8260726370403789\n","Avg recall score:  0.7291986359761295\n","------------------------------------\n","Class 0 size is 67 times Class 1 size.\n","Avg precision score:  0.8227869799691835\n","Avg recall score:  0.7115942028985507\n","------------------------------------\n","Class 0 size is 68 times Class 1 size.\n","Avg precision score:  0.8268456112852665\n","Avg recall score:  0.7174765558397271\n","------------------------------------\n","Class 0 size is 69 times Class 1 size.\n","Avg precision score:  0.8387800698327015\n","Avg recall score:  0.7203324808184143\n","------------------------------------\n","Class 0 size is 70 times Class 1 size.\n","Avg precision score:  0.815710703715417\n","Avg recall score:  0.717391304347826\n","------------------------------------\n","Class 0 size is 71 times Class 1 size.\n","Avg precision score:  0.8355509691657698\n","Avg recall score:  0.7408780903665814\n","------------------------------------\n","Class 0 size is 72 times Class 1 size.\n","Avg precision score:  0.8339232547854725\n","Avg recall score:  0.7144075021312873\n","------------------------------------\n","Class 0 size is 73 times Class 1 size.\n","Avg precision score:  0.8347338777059624\n","Avg recall score:  0.7027706734867859\n","------------------------------------\n","Class 0 size is 74 times Class 1 size.\n","Avg precision score:  0.8376114955955911\n","Avg recall score:  0.7176044330775788\n","------------------------------------\n","Class 0 size is 75 times Class 1 size.\n","Avg precision score:  0.8369881201956673\n","Avg recall score:  0.7144927536231884\n","------------------------------------\n","Class 0 size is 76 times Class 1 size.\n","Avg precision score:  0.8421503569529886\n","Avg recall score:  0.723231031543052\n","------------------------------------\n","Class 0 size is 77 times Class 1 size.\n","Avg precision score:  0.8452461584537057\n","Avg recall score:  0.6999573742540495\n","------------------------------------\n","Class 0 size is 78 times Class 1 size.\n","Avg precision score:  0.8525111408199644\n","Avg recall score:  0.7202898550724637\n","------------------------------------\n","Class 0 size is 79 times Class 1 size.\n","Avg precision score:  0.8281287933282382\n","Avg recall score:  0.7261295822676896\n","------------------------------------\n","Class 0 size is 80 times Class 1 size.\n","Avg precision score:  0.8401424206992889\n","Avg recall score:  0.7115942028985507\n","------------------------------------\n","Class 0 size is 81 times Class 1 size.\n","Avg precision score:  0.8368119124408151\n","Avg recall score:  0.7145780051150894\n","------------------------------------\n","Class 0 size is 82 times Class 1 size.\n","Avg precision score:  0.8513735400959822\n","Avg recall score:  0.7203324808184144\n","------------------------------------\n","Class 0 size is 83 times Class 1 size.\n","Avg precision score:  0.8507891138628519\n","Avg recall score:  0.7116368286445012\n","------------------------------------\n","Class 0 size is 84 times Class 1 size.\n","Avg precision score:  0.8443737666340734\n","Avg recall score:  0.7086530264279625\n","------------------------------------\n","Class 0 size is 85 times Class 1 size.\n","Avg precision score:  0.8608185271230333\n","Avg recall score:  0.708695652173913\n","------------------------------------\n","Class 0 size is 86 times Class 1 size.\n","Avg precision score:  0.8519634521360147\n","Avg recall score:  0.6999147485080989\n","------------------------------------\n","Class 0 size is 87 times Class 1 size.\n","Avg precision score:  0.8440251572327044\n","Avg recall score:  0.6970588235294117\n","------------------------------------\n","Class 0 size is 88 times Class 1 size.\n","Avg precision score:  0.8494407952810601\n","Avg recall score:  0.7030690537084399\n","------------------------------------\n","Class 0 size is 89 times Class 1 size.\n","Avg precision score:  0.8569484912086699\n","Avg recall score:  0.7116368286445012\n","------------------------------------\n","Class 0 size is 90 times Class 1 size.\n","Avg precision score:  0.8612183209493562\n","Avg recall score:  0.7057971014492753\n","------------------------------------\n","Class 0 size is 91 times Class 1 size.\n","Avg precision score:  0.8616724502146831\n","Avg recall score:  0.7028559249786871\n","------------------------------------\n","Class 0 size is 92 times Class 1 size.\n","Avg precision score:  0.8538458057757949\n","Avg recall score:  0.7145353793691389\n","------------------------------------\n","Class 0 size is 93 times Class 1 size.\n","Avg precision score:  0.8502955887271794\n","Avg recall score:  0.7115942028985507\n","------------------------------------\n","Class 0 size is 94 times Class 1 size.\n","Avg precision score:  0.8473332809143426\n","Avg recall score:  0.7086530264279625\n","------------------------------------\n","Class 0 size is 95 times Class 1 size.\n","Avg precision score:  0.851251082062198\n","Avg recall score:  0.6913469735720374\n","------------------------------------\n","Class 0 size is 96 times Class 1 size.\n","Avg precision score:  0.8608053751803751\n","Avg recall score:  0.6970588235294117\n","------------------------------------\n","Class 0 size is 97 times Class 1 size.\n","Avg precision score:  0.8604356423764635\n","Avg recall score:  0.7028985507246377\n","------------------------------------\n","Class 0 size is 98 times Class 1 size.\n","Avg precision score:  0.8606632322115464\n","Avg recall score:  0.7058397271952259\n","------------------------------------\n","Class 0 size is 99 times Class 1 size.\n","Avg precision score:  0.8615497344617152\n","Avg recall score:  0.6912190963341859\n","------------------------------------\n","Class 0 size is 100 times Class 1 size.\n","Avg precision score:  0.8701470950629384\n","Avg recall score:  0.7028559249786871\n","------------------------------------\n","Class 0 size is 101 times Class 1 size.\n","Avg precision score:  0.8602507066414239\n","Avg recall score:  0.6824808184143223\n","------------------------------------\n","Class 0 size is 102 times Class 1 size.\n","Avg precision score:  0.8685888146126285\n","Avg recall score:  0.7115942028985507\n","------------------------------------\n","Class 0 size is 103 times Class 1 size.\n","Avg precision score:  0.8484194642431019\n","Avg recall score:  0.6884484228473998\n","------------------------------------\n","Class 0 size is 104 times Class 1 size.\n","Avg precision score:  0.8678637709336752\n","Avg recall score:  0.6882352941176471\n","------------------------------------\n","Class 0 size is 105 times Class 1 size.\n","Avg precision score:  0.8731217958881666\n","Avg recall score:  0.6736572890025575\n","------------------------------------\n","Class 0 size is 106 times Class 1 size.\n","Avg precision score:  0.8516442236653301\n","Avg recall score:  0.6999573742540495\n","------------------------------------\n","Class 0 size is 107 times Class 1 size.\n","Avg precision score:  0.8717801481582942\n","Avg recall score:  0.6970588235294117\n","------------------------------------\n","Class 0 size is 108 times Class 1 size.\n","Avg precision score:  0.8651009309733139\n","Avg recall score:  0.708610400682012\n","------------------------------------\n","Class 0 size is 109 times Class 1 size.\n","Avg precision score:  0.8566307169890381\n","Avg recall score:  0.6941602728047741\n","------------------------------------\n","Class 0 size is 110 times Class 1 size.\n","Avg precision score:  0.8762085245847844\n","Avg recall score:  0.6854219948849105\n","------------------------------------\n","Class 0 size is 111 times Class 1 size.\n","Avg precision score:  0.8698846138680232\n","Avg recall score:  0.6823955669224212\n","------------------------------------\n","Class 0 size is 112 times Class 1 size.\n","Avg precision score:  0.8741775768091558\n","Avg recall score:  0.6767263427109975\n","------------------------------------\n","Class 0 size is 113 times Class 1 size.\n","Avg precision score:  0.8764804390655785\n","Avg recall score:  0.6854219948849105\n","------------------------------------\n","Class 0 size is 114 times Class 1 size.\n","Avg precision score:  0.870565309700736\n","Avg recall score:  0.6884057971014493\n","------------------------------------\n","Class 0 size is 115 times Class 1 size.\n","Avg precision score:  0.8727402227402227\n","Avg recall score:  0.6474850809889173\n","------------------------------------\n","Class 0 size is 116 times Class 1 size.\n","Avg precision score:  0.8833124510976187\n","Avg recall score:  0.6881500426257459\n","------------------------------------\n","Class 0 size is 117 times Class 1 size.\n","Avg precision score:  0.8653830360308656\n","Avg recall score:  0.6764705882352942\n","------------------------------------\n","Class 0 size is 118 times Class 1 size.\n","Avg precision score:  0.8850414078674949\n","Avg recall score:  0.6824808184143223\n","------------------------------------\n","Class 0 size is 119 times Class 1 size.\n","Avg precision score:  0.8719964488527652\n","Avg recall score:  0.6941602728047741\n","------------------------------------\n","Class 0 size is 120 times Class 1 size.\n","Avg precision score:  0.8716031609067227\n","Avg recall score:  0.673614663256607\n","------------------------------------\n","Class 0 size is 121 times Class 1 size.\n","Avg precision score:  0.8833100130004155\n","Avg recall score:  0.708610400682012\n","------------------------------------\n","Class 0 size is 122 times Class 1 size.\n","Avg precision score:  0.8724786324786326\n","Avg recall score:  0.6795822676896847\n","------------------------------------\n","Class 0 size is 123 times Class 1 size.\n","Avg precision score:  0.8729255986042066\n","Avg recall score:  0.6709718670076728\n","------------------------------------\n","Class 0 size is 124 times Class 1 size.\n","Avg precision score:  0.8706427251638317\n","Avg recall score:  0.6853367433930094\n","------------------------------------\n","Class 0 size is 125 times Class 1 size.\n","Avg precision score:  0.8810162840788974\n","Avg recall score:  0.6971440750213128\n","------------------------------------\n","Class 0 size is 126 times Class 1 size.\n","Avg precision score:  0.8707553715000523\n","Avg recall score:  0.6707161125319694\n","------------------------------------\n","Class 0 size is 127 times Class 1 size.\n","Avg precision score:  0.8723956835662825\n","Avg recall score:  0.6796248934356351\n","------------------------------------\n","Class 0 size is 128 times Class 1 size.\n","Avg precision score:  0.8810965939945437\n","Avg recall score:  0.6910912190963342\n","------------------------------------\n","Class 0 size is 129 times Class 1 size.\n","Avg precision score:  0.8690207385380969\n","Avg recall score:  0.6619352088661552\n","------------------------------------\n","Class 0 size is 130 times Class 1 size.\n","Avg precision score:  0.8804252285285056\n","Avg recall score:  0.6707161125319694\n","------------------------------------\n","Class 0 size is 131 times Class 1 size.\n","Avg precision score:  0.8871224838826626\n","Avg recall score:  0.6942028985507246\n","------------------------------------\n","Class 0 size is 132 times Class 1 size.\n","Avg precision score:  0.8830822880822881\n","Avg recall score:  0.6853367433930094\n","------------------------------------\n","Class 0 size is 133 times Class 1 size.\n","Avg precision score:  0.8623357963875206\n","Avg recall score:  0.6737851662404093\n","------------------------------------\n","Class 0 size is 134 times Class 1 size.\n","Avg precision score:  0.8725498764020599\n","Avg recall score:  0.670843989769821\n","------------------------------------\n","Class 0 size is 135 times Class 1 size.\n","Avg precision score:  0.8828511066969517\n","Avg recall score:  0.6647911338448422\n","------------------------------------\n","Class 0 size is 136 times Class 1 size.\n","Avg precision score:  0.8680302109260642\n","Avg recall score:  0.6590366581415175\n","------------------------------------\n","Class 0 size is 137 times Class 1 size.\n","Avg precision score:  0.8826524735285151\n","Avg recall score:  0.6794970161977835\n","------------------------------------\n","Class 0 size is 138 times Class 1 size.\n","Avg precision score:  0.8776570233954122\n","Avg recall score:  0.7086104006820119\n","------------------------------------\n","Class 0 size is 139 times Class 1 size.\n","Avg precision score:  0.8809339239571798\n","Avg recall score:  0.6622762148337596\n","------------------------------------\n","Class 0 size is 140 times Class 1 size.\n","Avg precision score:  0.8770925262294375\n","Avg recall score:  0.6501278772378516\n","------------------------------------\n","Class 0 size is 141 times Class 1 size.\n","Avg precision score:  0.8774770476397021\n","Avg recall score:  0.6707587382779199\n","------------------------------------\n","Class 0 size is 142 times Class 1 size.\n","Avg precision score:  0.8778170578576259\n","Avg recall score:  0.6767263427109975\n","------------------------------------\n","Class 0 size is 143 times Class 1 size.\n","Avg precision score:  0.8795450864924549\n","Avg recall score:  0.6678601875532821\n","------------------------------------\n","Class 0 size is 144 times Class 1 size.\n","Avg precision score:  0.8856503496503496\n","Avg recall score:  0.6620204603580563\n","------------------------------------\n","Class 0 size is 145 times Class 1 size.\n","Avg precision score:  0.8784278096710594\n","Avg recall score:  0.6795822676896845\n","------------------------------------\n","Class 0 size is 146 times Class 1 size.\n","Avg precision score:  0.8706813545955147\n","Avg recall score:  0.6531969309462916\n","------------------------------------\n","Class 0 size is 147 times Class 1 size.\n","Avg precision score:  0.8776672522324697\n","Avg recall score:  0.6534100596760444\n","------------------------------------\n","Class 0 size is 148 times Class 1 size.\n","Avg precision score:  0.8787075927445083\n","Avg recall score:  0.6414748508098892\n","------------------------------------\n","Class 0 size is 149 times Class 1 size.\n","Avg precision score:  0.8849614613589768\n","Avg recall score:  0.6590366581415175\n","------------------------------------\n","Class 0 size is 150 times Class 1 size.\n","Avg precision score:  0.8878472690100597\n","Avg recall score:  0.6797101449275362\n","------------------------------------\n","Class 0 size is 151 times Class 1 size.\n","Avg precision score:  0.8764825215194371\n","Avg recall score:  0.6327791986359761\n","------------------------------------\n","Class 0 size is 152 times Class 1 size.\n","Avg precision score:  0.8798543328017013\n","Avg recall score:  0.6736999147485081\n","------------------------------------\n","Class 0 size is 153 times Class 1 size.\n","Avg precision score:  0.884237384681336\n","Avg recall score:  0.6532821824381927\n","------------------------------------\n","Class 0 size is 154 times Class 1 size.\n","Avg precision score:  0.8852118525612761\n","Avg recall score:  0.685464620630861\n","------------------------------------\n","Class 0 size is 155 times Class 1 size.\n","Avg precision score:  0.8831952070410521\n","Avg recall score:  0.6505541346973572\n","------------------------------------\n","Class 0 size is 156 times Class 1 size.\n","Avg precision score:  0.8846631157653999\n","Avg recall score:  0.6824808184143223\n","------------------------------------\n","Class 0 size is 157 times Class 1 size.\n","Avg precision score:  0.8802448486842602\n","Avg recall score:  0.6473998294970162\n","------------------------------------\n","Class 0 size is 158 times Class 1 size.\n","Avg precision score:  0.8848769964295098\n","Avg recall score:  0.6560954816709292\n","------------------------------------\n","Class 0 size is 159 times Class 1 size.\n","Avg precision score:  0.8812714793519747\n","Avg recall score:  0.658994032395567\n","------------------------------------\n","Class 0 size is 160 times Class 1 size.\n","Avg precision score:  0.8803369463727521\n","Avg recall score:  0.6328644501278773\n","------------------------------------\n","Class 0 size is 161 times Class 1 size.\n","Avg precision score:  0.8779277918326318\n","Avg recall score:  0.638533674339301\n","------------------------------------\n","Class 0 size is 162 times Class 1 size.\n","Avg precision score:  0.8829564228244058\n","Avg recall score:  0.6620204603580563\n","------------------------------------\n","Class 0 size is 163 times Class 1 size.\n","Avg precision score:  0.8870856874218219\n","Avg recall score:  0.650383631713555\n","------------------------------------\n","Class 0 size is 164 times Class 1 size.\n","Avg precision score:  0.8781770998455943\n","Avg recall score:  0.635848252344416\n","------------------------------------\n","Class 0 size is 165 times Class 1 size.\n","Avg precision score:  0.8816823899371069\n","Avg recall score:  0.6562233589087809\n","------------------------------------\n","Class 0 size is 166 times Class 1 size.\n","Avg precision score:  0.8870005220374375\n","Avg recall score:  0.6472719522591646\n","------------------------------------\n","Class 0 size is 167 times Class 1 size.\n","Avg precision score:  0.881994301994302\n","Avg recall score:  0.6620204603580563\n","------------------------------------\n","Class 0 size is 168 times Class 1 size.\n","Avg precision score:  0.886462011905963\n","Avg recall score:  0.6649616368286445\n","------------------------------------\n","Class 0 size is 169 times Class 1 size.\n","Avg precision score:  0.8838618524332811\n","Avg recall score:  0.6532821824381927\n","------------------------------------\n","Class 0 size is 170 times Class 1 size.\n","Avg precision score:  0.8845918003565062\n","Avg recall score:  0.6591645353793691\n","------------------------------------\n","Class 0 size is 171 times Class 1 size.\n","Avg precision score:  0.8793012149395129\n","Avg recall score:  0.6241687979539642\n","------------------------------------\n","Class 0 size is 172 times Class 1 size.\n","Avg precision score:  0.8837844829942094\n","Avg recall score:  0.6329923273657289\n","------------------------------------\n","Class 0 size is 173 times Class 1 size.\n","Avg precision score:  0.8814858345891118\n","Avg recall score:  0.6533248081841434\n","------------------------------------\n","Class 0 size is 174 times Class 1 size.\n","Avg precision score:  0.8840935452932515\n","Avg recall score:  0.6328644501278773\n","------------------------------------\n","Class 0 size is 175 times Class 1 size.\n","Avg precision score:  0.879245314649658\n","Avg recall score:  0.6417306052855926\n","------------------------------------\n","Class 0 size is 176 times Class 1 size.\n","Avg precision score:  0.8822602954225168\n","Avg recall score:  0.6649190110826939\n","------------------------------------\n","Class 0 size is 177 times Class 1 size.\n","Avg precision score:  0.8830250530619687\n","Avg recall score:  0.6269820971867008\n","------------------------------------\n","Class 0 size is 178 times Class 1 size.\n","Avg precision score:  0.8853283970931031\n","Avg recall score:  0.6384910485933505\n","------------------------------------\n","Class 0 size is 179 times Class 1 size.\n","Avg precision score:  0.8849121466768526\n","Avg recall score:  0.6590792838874682\n","------------------------------------\n","Class 0 size is 180 times Class 1 size.\n","Avg precision score:  0.881917004828056\n","Avg recall score:  0.6387894288150043\n","------------------------------------\n","Class 0 size is 181 times Class 1 size.\n","Avg precision score:  0.8852146324510365\n","Avg recall score:  0.6387894288150042\n","------------------------------------\n","Class 0 size is 182 times Class 1 size.\n","Avg precision score:  0.883312967356094\n","Avg recall score:  0.6473998294970162\n","------------------------------------\n","Class 0 size is 183 times Class 1 size.\n","Avg precision score:  0.8853996569468269\n","Avg recall score:  0.6591219096334185\n","------------------------------------\n","Class 0 size is 184 times Class 1 size.\n","Avg precision score:  0.887053186054296\n","Avg recall score:  0.6503836317135551\n","------------------------------------\n","Class 0 size is 185 times Class 1 size.\n","Avg precision score:  0.8826905075325435\n","Avg recall score:  0.6240409207161125\n","------------------------------------\n","Class 0 size is 186 times Class 1 size.\n","Avg precision score:  0.8836834381551363\n","Avg recall score:  0.6329497016197784\n","------------------------------------\n","Class 0 size is 187 times Class 1 size.\n","Avg precision score:  0.883110048949175\n","Avg recall score:  0.6649616368286446\n","------------------------------------\n","Class 0 size is 188 times Class 1 size.\n","Avg precision score:  0.8821010182110143\n","Avg recall score:  0.6386189258312022\n","------------------------------------\n","Class 0 size is 189 times Class 1 size.\n","Avg precision score:  0.8799553110781474\n","Avg recall score:  0.6298806479113386\n","------------------------------------\n","Class 0 size is 190 times Class 1 size.\n","Avg precision score:  0.8792577088107881\n","Avg recall score:  0.6415601023017904\n","------------------------------------\n","Class 0 size is 191 times Class 1 size.\n","Avg precision score:  0.8838208628219727\n","Avg recall score:  0.6503836317135551\n","------------------------------------\n","Class 0 size is 192 times Class 1 size.\n","Avg precision score:  0.8818534080298785\n","Avg recall score:  0.618158567774936\n","------------------------------------\n","Class 0 size is 193 times Class 1 size.\n","Avg precision score:  0.8811406423034331\n","Avg recall score:  0.6386615515771525\n","------------------------------------\n","Class 0 size is 194 times Class 1 size.\n","Avg precision score:  0.8823491307454157\n","Avg recall score:  0.6560954816709292\n","------------------------------------\n","Class 0 size is 195 times Class 1 size.\n","Avg precision score:  0.8837435285000634\n","Avg recall score:  0.6269394714407504\n","------------------------------------\n","Class 0 size is 196 times Class 1 size.\n","Avg precision score:  0.8861802243877716\n","Avg recall score:  0.6444160272804774\n","------------------------------------\n","Class 0 size is 197 times Class 1 size.\n","Avg precision score:  0.8861717361439891\n","Avg recall score:  0.6416453537936915\n","------------------------------------\n","Class 0 size is 198 times Class 1 size.\n","Avg precision score:  0.8865263560915736\n","Avg recall score:  0.6476555839727196\n","------------------------------------\n","Class 0 size is 199 times Class 1 size.\n","Avg precision score:  0.8858196219826402\n","Avg recall score:  0.6182864450127877\n","------------------------------------\n","Class 0 size is 200 times Class 1 size.\n","Avg precision score:  0.8843319379033664\n","Avg recall score:  0.6328644501278773\n","------------------------------------\n","Class 0 size is 201 times Class 1 size.\n","Avg precision score:  0.879468286099865\n","Avg recall score:  0.6445865302642797\n","------------------------------------\n","Class 0 size is 202 times Class 1 size.\n","Avg precision score:  0.8828705317163766\n","Avg recall score:  0.6241261722080137\n","------------------------------------\n","Class 0 size is 203 times Class 1 size.\n","Avg precision score:  0.885675173882721\n","Avg recall score:  0.6182011935208866\n","------------------------------------\n","Class 0 size is 204 times Class 1 size.\n","Avg precision score:  0.878364158401074\n","Avg recall score:  0.6211849957374255\n","------------------------------------\n","Class 0 size is 205 times Class 1 size.\n","Avg precision score:  0.8829619927549057\n","Avg recall score:  0.6271952259164536\n","------------------------------------\n","Class 0 size is 206 times Class 1 size.\n","Avg precision score:  0.884346881095175\n","Avg recall score:  0.6328218243819268\n","------------------------------------\n","Class 0 size is 207 times Class 1 size.\n","Avg precision score:  0.8766451849519772\n","Avg recall score:  0.6270247229326513\n","------------------------------------\n","Class 0 size is 208 times Class 1 size.\n","Avg precision score:  0.8871279368060723\n","Avg recall score:  0.6297953964194374\n","------------------------------------\n","Class 0 size is 209 times Class 1 size.\n","Avg precision score:  0.8807684514067493\n","Avg recall score:  0.6124040920716112\n","------------------------------------\n","Class 0 size is 210 times Class 1 size.\n","Avg precision score:  0.88120386504971\n","Avg recall score:  0.6153026427962489\n","------------------------------------\n","Class 0 size is 211 times Class 1 size.\n","Avg precision score:  0.8829946747957635\n","Avg recall score:  0.6210997442455243\n","------------------------------------\n","Class 0 size is 212 times Class 1 size.\n","Avg precision score:  0.8825906420623401\n","Avg recall score:  0.6240409207161125\n","------------------------------------\n","Class 0 size is 213 times Class 1 size.\n","Avg precision score:  0.887436037879989\n","Avg recall score:  0.6298380221653879\n","------------------------------------\n","Class 0 size is 214 times Class 1 size.\n","Avg precision score:  0.8787440442157424\n","Avg recall score:  0.6066496163682864\n","------------------------------------\n","Class 0 size is 215 times Class 1 size.\n","Avg precision score:  0.884094270509365\n","Avg recall score:  0.6326939471440751\n","------------------------------------\n","Class 0 size is 216 times Class 1 size.\n","Avg precision score:  0.8790382208529893\n","Avg recall score:  0.6036658141517476\n","------------------------------------\n","Class 0 size is 217 times Class 1 size.\n","Avg precision score:  0.8839345316021465\n","Avg recall score:  0.6328218243819268\n","------------------------------------\n","Class 0 size is 218 times Class 1 size.\n","Avg precision score:  0.8870517163853663\n","Avg recall score:  0.6240835464620631\n","------------------------------------\n","Class 0 size is 219 times Class 1 size.\n","Avg precision score:  0.8736882372767105\n","Avg recall score:  0.6123188405797102\n","------------------------------------\n","Class 0 size is 220 times Class 1 size.\n","Avg precision score:  0.8772560772560773\n","Avg recall score:  0.6124040920716112\n","------------------------------------\n","Class 0 size is 221 times Class 1 size.\n","Avg precision score:  0.8836715557286198\n","Avg recall score:  0.6327365728900256\n","------------------------------------\n","Class 0 size is 222 times Class 1 size.\n","Avg precision score:  0.8830102707749766\n","Avg recall score:  0.6241687979539641\n","------------------------------------\n","Class 0 size is 223 times Class 1 size.\n","Avg precision score:  0.8821550671550671\n","Avg recall score:  0.6210997442455243\n","------------------------------------\n","Class 0 size is 224 times Class 1 size.\n","Avg precision score:  0.8809812409812409\n","Avg recall score:  0.6212702472293264\n","------------------------------------\n","Class 0 size is 225 times Class 1 size.\n","Avg precision score:  0.8896134163894622\n","Avg recall score:  0.6182438192668371\n","------------------------------------\n","Class 0 size is 226 times Class 1 size.\n","Avg precision score:  0.8801945808328787\n","Avg recall score:  0.6124040920716112\n","------------------------------------\n","Class 0 size is 227 times Class 1 size.\n","Avg precision score:  0.893678769621056\n","Avg recall score:  0.6213554987212276\n","------------------------------------\n","Class 0 size is 228 times Class 1 size.\n","Avg precision score:  0.888418716015407\n","Avg recall score:  0.6124040920716112\n","------------------------------------\n","Class 0 size is 229 times Class 1 size.\n","Avg precision score:  0.8845396357417263\n","Avg recall score:  0.6064791133844842\n","------------------------------------\n","Class 0 size is 230 times Class 1 size.\n","Avg precision score:  0.8810065466448446\n","Avg recall score:  0.6153878942881501\n","------------------------------------\n","Class 0 size is 231 times Class 1 size.\n","Avg precision score:  0.8814932028457865\n","Avg recall score:  0.6124040920716112\n","------------------------------------\n","Class 0 size is 232 times Class 1 size.\n","Avg precision score:  0.8844106531418205\n","Avg recall score:  0.6153878942881501\n","------------------------------------\n","Class 0 size is 233 times Class 1 size.\n","Avg precision score:  0.8861771944216571\n","Avg recall score:  0.6211849957374255\n","------------------------------------\n","Class 0 size is 234 times Class 1 size.\n","Avg precision score:  0.8808724259060601\n","Avg recall score:  0.6326939471440749\n","------------------------------------\n","Class 0 size is 235 times Class 1 size.\n","Avg precision score:  0.8795806807571512\n","Avg recall score:  0.6065643648763853\n","------------------------------------\n","Class 0 size is 236 times Class 1 size.\n","Avg precision score:  0.8826837313629767\n","Avg recall score:  0.6037510656436487\n","------------------------------------\n","Class 0 size is 237 times Class 1 size.\n","Avg precision score:  0.8788453744836723\n","Avg recall score:  0.6210997442455243\n","------------------------------------\n","Class 0 size is 238 times Class 1 size.\n","Avg precision score:  0.8823803709517997\n","Avg recall score:  0.6240835464620631\n","------------------------------------\n","Class 0 size is 239 times Class 1 size.\n","Avg precision score:  0.8818664668664669\n","Avg recall score:  0.6153026427962489\n","------------------------------------\n","Class 0 size is 240 times Class 1 size.\n","Avg precision score:  0.8817231789959656\n","Avg recall score:  0.6182438192668371\n","------------------------------------\n","Class 0 size is 241 times Class 1 size.\n","Avg precision score:  0.8848929217076901\n","Avg recall score:  0.6123614663256607\n","------------------------------------\n","Class 0 size is 242 times Class 1 size.\n","Avg precision score:  0.8810389158318289\n","Avg recall score:  0.6153026427962489\n","------------------------------------\n","Class 0 size is 243 times Class 1 size.\n","Avg precision score:  0.8813426573426574\n","Avg recall score:  0.5920289855072463\n","------------------------------------\n","Class 0 size is 244 times Class 1 size.\n","Avg precision score:  0.88120386504971\n","Avg recall score:  0.6153026427962489\n","------------------------------------\n","Class 0 size is 245 times Class 1 size.\n","Avg precision score:  0.8875836312789834\n","Avg recall score:  0.6066069906223358\n","------------------------------------\n","Class 0 size is 246 times Class 1 size.\n","Avg precision score:  0.8829555469986736\n","Avg recall score:  0.6269394714407502\n","------------------------------------\n","Class 0 size is 247 times Class 1 size.\n","Avg precision score:  0.8790276390276389\n","Avg recall score:  0.6037084398976982\n","------------------------------------\n","Class 0 size is 248 times Class 1 size.\n","Avg precision score:  0.8830834697217675\n","Avg recall score:  0.6007246376811594\n","------------------------------------\n","Class 0 size is 249 times Class 1 size.\n","Avg precision score:  0.8800197938707255\n","Avg recall score:  0.6065217391304347\n","------------------------------------\n","Class 0 size is 250 times Class 1 size.\n","Avg precision score:  0.8804527629233512\n","Avg recall score:  0.5920289855072463\n","------------------------------------\n","Class 0 size is 251 times Class 1 size.\n","Avg precision score:  0.8858014184397163\n","Avg recall score:  0.6007246376811594\n","------------------------------------\n","Class 0 size is 252 times Class 1 size.\n","Avg precision score:  0.8905760225355255\n","Avg recall score:  0.6066496163682864\n","------------------------------------\n","Class 0 size is 253 times Class 1 size.\n","Avg precision score:  0.8804667922815608\n","Avg recall score:  0.609462915601023\n","------------------------------------\n","Class 0 size is 254 times Class 1 size.\n","Avg precision score:  0.884134267980113\n","Avg recall score:  0.6095055413469735\n","------------------------------------\n","Class 0 size is 255 times Class 1 size.\n","Avg precision score:  0.881657152371438\n","Avg recall score:  0.5919863597612958\n","------------------------------------\n","Class 0 size is 256 times Class 1 size.\n","Avg precision score:  0.8834983638845608\n","Avg recall score:  0.6270247229326513\n","------------------------------------\n","Class 0 size is 257 times Class 1 size.\n","Avg precision score:  0.8877542782420832\n","Avg recall score:  0.6066069906223358\n","------------------------------------\n","Class 0 size is 258 times Class 1 size.\n","Avg precision score:  0.8821203953279426\n","Avg recall score:  0.6181159420289856\n","------------------------------------\n","Class 0 size is 259 times Class 1 size.\n","Avg precision score:  0.885101738808731\n","Avg recall score:  0.6211423699914749\n","------------------------------------\n","Class 0 size is 260 times Class 1 size.\n","Avg precision score:  0.8798265361791199\n","Avg recall score:  0.6035805626598465\n","------------------------------------\n","Class 0 size is 261 times Class 1 size.\n","Avg precision score:  0.8784321602469287\n","Avg recall score:  0.600852514919011\n","------------------------------------\n","Class 0 size is 262 times Class 1 size.\n","Avg precision score:  0.8787661885591017\n","Avg recall score:  0.6037084398976982\n","------------------------------------\n","Class 0 size is 263 times Class 1 size.\n","Avg precision score:  0.8822624434389141\n","Avg recall score:  0.5978687127024722\n","------------------------------------\n","Class 0 size is 264 times Class 1 size.\n","Avg precision score:  0.8731770040179303\n","Avg recall score:  0.5920289855072465\n","------------------------------------\n","Class 0 size is 265 times Class 1 size.\n","Avg precision score:  0.8787244953627933\n","Avg recall score:  0.6007246376811594\n","------------------------------------\n","Class 0 size is 266 times Class 1 size.\n","Avg precision score:  0.8863328495403968\n","Avg recall score:  0.621227621483376\n","------------------------------------\n","Class 0 size is 267 times Class 1 size.\n","Avg precision score:  0.8861367711090242\n","Avg recall score:  0.6210997442455243\n","------------------------------------\n","Class 0 size is 268 times Class 1 size.\n","Avg precision score:  0.8866163027424054\n","Avg recall score:  0.621227621483376\n","------------------------------------\n","Class 0 size is 269 times Class 1 size.\n","Avg precision score:  0.881723783853164\n","Avg recall score:  0.6184143222506394\n","------------------------------------\n","Class 0 size is 270 times Class 1 size.\n","Avg precision score:  0.8802134097786272\n","Avg recall score:  0.6095055413469735\n","------------------------------------\n","Class 0 size is 271 times Class 1 size.\n","Avg precision score:  0.8829900489306723\n","Avg recall score:  0.6035805626598465\n","------------------------------------\n","Class 0 size is 272 times Class 1 size.\n","Avg precision score:  0.8848929217076901\n","Avg recall score:  0.6123614663256607\n","------------------------------------\n","Class 0 size is 273 times Class 1 size.\n","Avg precision score:  0.886251984860329\n","Avg recall score:  0.6211849957374255\n","------------------------------------\n","Class 0 size is 274 times Class 1 size.\n","Avg precision score:  0.8874768007877776\n","Avg recall score:  0.6035805626598465\n","------------------------------------\n","Class 0 size is 275 times Class 1 size.\n","Avg precision score:  0.8837618654261409\n","Avg recall score:  0.6065643648763853\n","------------------------------------\n","Class 0 size is 276 times Class 1 size.\n","Avg precision score:  0.8810221333613946\n","Avg recall score:  0.592071611253197\n","------------------------------------\n","Class 0 size is 277 times Class 1 size.\n","Avg precision score:  0.8789011610517441\n","Avg recall score:  0.6007246376811594\n","------------------------------------\n","Class 0 size is 278 times Class 1 size.\n","Avg precision score:  0.8875836312789834\n","Avg recall score:  0.6066069906223358\n","------------------------------------\n","Class 0 size is 279 times Class 1 size.\n","Avg precision score:  0.8897800280653847\n","Avg recall score:  0.618158567774936\n","------------------------------------\n","Class 0 size is 280 times Class 1 size.\n","Avg precision score:  0.880071692984575\n","Avg recall score:  0.5891304347826087\n","------------------------------------\n","Class 0 size is 281 times Class 1 size.\n","Avg precision score:  0.8833979647505483\n","Avg recall score:  0.6006820119352089\n","------------------------------------\n","Class 0 size is 282 times Class 1 size.\n","Avg precision score:  0.8813725490196077\n","Avg recall score:  0.5978687127024722\n","------------------------------------\n","Class 0 size is 283 times Class 1 size.\n","Avg precision score:  0.8816631590024201\n","Avg recall score:  0.5949701619778347\n","------------------------------------\n","Class 0 size is 284 times Class 1 size.\n","Avg precision score:  0.886593468744052\n","Avg recall score:  0.6066069906223358\n","------------------------------------\n","Class 0 size is 285 times Class 1 size.\n","Avg precision score:  0.8781694537346711\n","Avg recall score:  0.5978260869565217\n","------------------------------------\n","Class 0 size is 286 times Class 1 size.\n","Avg precision score:  0.8823934556010029\n","Avg recall score:  0.6008098891730604\n","------------------------------------\n","Class 0 size is 287 times Class 1 size.\n","Avg precision score:  0.8807684514067493\n","Avg recall score:  0.6124040920716112\n","------------------------------------\n","Class 0 size is 288 times Class 1 size.\n","Avg precision score:  0.8878375350140055\n","Avg recall score:  0.592071611253197\n","------------------------------------\n","Class 0 size is 289 times Class 1 size.\n","Avg precision score:  0.8790382208529893\n","Avg recall score:  0.6036658141517476\n","------------------------------------\n","Class 0 size is 290 times Class 1 size.\n","Avg precision score:  0.8854271218977102\n","Avg recall score:  0.5979113384484227\n","------------------------------------\n","Class 0 size is 291 times Class 1 size.\n","Avg precision score:  0.8816563828328533\n","Avg recall score:  0.5949701619778345\n","------------------------------------\n","Class 0 size is 292 times Class 1 size.\n","Avg precision score:  0.8831923527524836\n","Avg recall score:  0.6006820119352089\n","------------------------------------\n","Class 0 size is 293 times Class 1 size.\n","Avg precision score:  0.8857606119370824\n","Avg recall score:  0.5949701619778347\n","------------------------------------\n","Class 0 size is 294 times Class 1 size.\n","Avg precision score:  0.8832783367653871\n","Avg recall score:  0.6006820119352089\n","------------------------------------\n","Class 0 size is 295 times Class 1 size.\n","Avg precision score:  0.8813494335122243\n","Avg recall score:  0.5920289855072465\n","------------------------------------\n","Class 0 size is 296 times Class 1 size.\n","Avg precision score:  0.8868662751516319\n","Avg recall score:  0.6036658141517476\n","------------------------------------\n","Class 0 size is 297 times Class 1 size.\n","Avg precision score:  0.8833971952119637\n","Avg recall score:  0.6036658141517476\n","------------------------------------\n","Class 0 size is 298 times Class 1 size.\n","Avg precision score:  0.8832088236966286\n","Avg recall score:  0.6037084398976982\n","------------------------------------\n","Class 0 size is 299 times Class 1 size.\n","Avg precision score:  0.884134267980113\n","Avg recall score:  0.6095055413469735\n","------------------------------------\n","Class 0 size is 300 times Class 1 size.\n","Avg precision score:  0.8840077208481093\n","Avg recall score:  0.6035805626598465\n","------------------------------------\n","Class 0 size is 301 times Class 1 size.\n","Avg precision score:  0.8852412744488216\n","Avg recall score:  0.5920289855072465\n","------------------------------------\n","Class 0 size is 302 times Class 1 size.\n","Avg precision score:  0.8847928724262513\n","Avg recall score:  0.5950127877237852\n","------------------------------------\n","Class 0 size is 303 times Class 1 size.\n","Avg precision score:  0.8814575470043554\n","Avg recall score:  0.5949701619778347\n","------------------------------------\n","Class 0 size is 304 times Class 1 size.\n","Avg precision score:  0.8810221333613946\n","Avg recall score:  0.592071611253197\n","------------------------------------\n","Class 0 size is 305 times Class 1 size.\n","Avg precision score:  0.8896695058715964\n","Avg recall score:  0.5919863597612958\n","------------------------------------\n","Class 0 size is 306 times Class 1 size.\n","Avg precision score:  0.8882167135190391\n","Avg recall score:  0.5861892583120205\n","------------------------------------\n","Class 0 size is 307 times Class 1 size.\n","Avg precision score:  0.885698600068938\n","Avg recall score:  0.5979113384484229\n","------------------------------------\n","Class 0 size is 308 times Class 1 size.\n","Avg precision score:  0.8836988543371522\n","Avg recall score:  0.6066069906223358\n","------------------------------------\n","Class 0 size is 309 times Class 1 size.\n","Avg precision score:  0.8851254627725217\n","Avg recall score:  0.5949701619778345\n","------------------------------------\n","Class 0 size is 310 times Class 1 size.\n","Avg precision score:  0.8831923527524836\n","Avg recall score:  0.6006820119352089\n","------------------------------------\n","Class 0 size is 311 times Class 1 size.\n","Avg precision score:  0.889167195519779\n","Avg recall score:  0.5919863597612958\n","------------------------------------\n","Class 0 size is 312 times Class 1 size.\n","Avg precision score:  0.8822624434389141\n","Avg recall score:  0.5978687127024722\n","------------------------------------\n","Class 0 size is 313 times Class 1 size.\n","Avg precision score:  0.8836988543371522\n","Avg recall score:  0.6066069906223358\n","------------------------------------\n","Class 0 size is 314 times Class 1 size.\n","Avg precision score:  0.8824087058891091\n","Avg recall score:  0.5978260869565217\n","------------------------------------\n","Class 0 size is 315 times Class 1 size.\n","Avg precision score:  0.8872736463006256\n","Avg recall score:  0.5832907075873829\n","------------------------------------\n","Class 0 size is 316 times Class 1 size.\n","Avg precision score:  0.8841310969732022\n","Avg recall score:  0.5862318840579711\n","------------------------------------\n","Class 0 size is 317 times Class 1 size.\n","Avg precision score:  0.8888541377759707\n","Avg recall score:  0.589087809036658\n","------------------------------------\n","Class 0 size is 318 times Class 1 size.\n","Avg precision score:  0.8833971952119637\n","Avg recall score:  0.6036658141517476\n","------------------------------------\n","Class 0 size is 319 times Class 1 size.\n","Avg precision score:  0.8880990564383175\n","Avg recall score:  0.592071611253197\n","------------------------------------\n","Class 0 size is 320 times Class 1 size.\n","Avg precision score:  0.8852133480554534\n","Avg recall score:  0.5920289855072463\n","------------------------------------\n","Class 0 size is 321 times Class 1 size.\n","Avg precision score:  0.8848058608058608\n","Avg recall score:  0.5891304347826087\n","------------------------------------\n","Class 0 size is 322 times Class 1 size.\n","Avg precision score:  0.8848058608058608\n","Avg recall score:  0.5891304347826087\n","------------------------------------\n","Class 0 size is 323 times Class 1 size.\n","Avg precision score:  0.8921972789115646\n","Avg recall score:  0.589087809036658\n","------------------------------------\n","Class 0 size is 324 times Class 1 size.\n","Avg precision score:  0.8827569391095228\n","Avg recall score:  0.5977834612105711\n","------------------------------------\n","Class 0 size is 325 times Class 1 size.\n","Avg precision score:  0.891556253270539\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 326 times Class 1 size.\n","Avg precision score:  0.8879484101332841\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 327 times Class 1 size.\n","Avg precision score:  0.8810221333613946\n","Avg recall score:  0.592071611253197\n","------------------------------------\n","Class 0 size is 328 times Class 1 size.\n","Avg precision score:  0.8803818772589537\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 329 times Class 1 size.\n","Avg precision score:  0.891882783882784\n","Avg recall score:  0.5891304347826087\n","------------------------------------\n","Class 0 size is 330 times Class 1 size.\n","Avg precision score:  0.8841774878108666\n","Avg recall score:  0.5891304347826087\n","------------------------------------\n","Class 0 size is 331 times Class 1 size.\n","Avg precision score:  0.8825284280936454\n","Avg recall score:  0.5978260869565217\n","------------------------------------\n","Class 0 size is 332 times Class 1 size.\n","Avg precision score:  0.8843212711983476\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 333 times Class 1 size.\n","Avg precision score:  0.8810221333613946\n","Avg recall score:  0.592071611253197\n","------------------------------------\n","Class 0 size is 334 times Class 1 size.\n","Avg precision score:  0.8810221333613946\n","Avg recall score:  0.592071611253197\n","------------------------------------\n","Class 0 size is 335 times Class 1 size.\n","Avg precision score:  0.8844448224633983\n","Avg recall score:  0.5891730605285593\n","------------------------------------\n","Class 0 size is 336 times Class 1 size.\n","Avg precision score:  0.8888903253609136\n","Avg recall score:  0.5950127877237852\n","------------------------------------\n","Class 0 size is 337 times Class 1 size.\n","Avg precision score:  0.8874588003358767\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 338 times Class 1 size.\n","Avg precision score:  0.8878051710194568\n","Avg recall score:  0.5832907075873827\n","------------------------------------\n","Class 0 size is 339 times Class 1 size.\n","Avg precision score:  0.8867815475232355\n","Avg recall score:  0.60076726342711\n","------------------------------------\n","Class 0 size is 340 times Class 1 size.\n","Avg precision score:  0.8844793301936159\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 341 times Class 1 size.\n","Avg precision score:  0.8831761933659632\n","Avg recall score:  0.5832907075873829\n","------------------------------------\n","Class 0 size is 342 times Class 1 size.\n","Avg precision score:  0.8844793301936159\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 343 times Class 1 size.\n","Avg precision score:  0.886226019049191\n","Avg recall score:  0.5977834612105711\n","------------------------------------\n","Class 0 size is 344 times Class 1 size.\n","Avg precision score:  0.8848058608058608\n","Avg recall score:  0.5891304347826087\n","------------------------------------\n","Class 0 size is 345 times Class 1 size.\n","Avg precision score:  0.8803473695287358\n","Avg recall score:  0.5891730605285593\n","------------------------------------\n","Class 0 size is 346 times Class 1 size.\n","Avg precision score:  0.8855615812758669\n","Avg recall score:  0.5919863597612958\n","------------------------------------\n","Class 0 size is 347 times Class 1 size.\n","Avg precision score:  0.8816563828328533\n","Avg recall score:  0.5949701619778345\n","------------------------------------\n","Class 0 size is 348 times Class 1 size.\n","Avg precision score:  0.8832888540031398\n","Avg recall score:  0.6006820119352089\n","------------------------------------\n","Class 0 size is 349 times Class 1 size.\n","Avg precision score:  0.8857322929171669\n","Avg recall score:  0.5948849104859335\n","------------------------------------\n","Class 0 size is 350 times Class 1 size.\n","Avg precision score:  0.8884187241330098\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 351 times Class 1 size.\n","Avg precision score:  0.887556253270539\n","Avg recall score:  0.5832907075873829\n","------------------------------------\n","Class 0 size is 352 times Class 1 size.\n","Avg precision score:  0.8877903511380157\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 353 times Class 1 size.\n","Avg precision score:  0.8877439603003513\n","Avg recall score:  0.5832907075873829\n","------------------------------------\n","Class 0 size is 354 times Class 1 size.\n","Avg precision score:  0.8838509571986218\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 355 times Class 1 size.\n","Avg precision score:  0.8843212711983476\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 356 times Class 1 size.\n","Avg precision score:  0.8832390201160966\n","Avg recall score:  0.580306905370844\n","------------------------------------\n","Class 0 size is 357 times Class 1 size.\n","Avg precision score:  0.8890656262505002\n","Avg recall score:  0.5919863597612958\n","------------------------------------\n","Class 0 size is 358 times Class 1 size.\n","Avg precision score:  0.8954956472099329\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 359 times Class 1 size.\n","Avg precision score:  0.8903097619740373\n","Avg recall score:  0.5978687127024724\n","------------------------------------\n","Class 0 size is 360 times Class 1 size.\n","Avg precision score:  0.8877439603003513\n","Avg recall score:  0.5832907075873829\n","------------------------------------\n","Class 0 size is 361 times Class 1 size.\n","Avg precision score:  0.8803818772589537\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 362 times Class 1 size.\n","Avg precision score:  0.881622187336473\n","Avg recall score:  0.5919863597612958\n","------------------------------------\n","Class 0 size is 363 times Class 1 size.\n","Avg precision score:  0.8912130402400195\n","Avg recall score:  0.5832907075873829\n","------------------------------------\n","Class 0 size is 364 times Class 1 size.\n","Avg precision score:  0.8807084078711984\n","Avg recall score:  0.5891304347826087\n","------------------------------------\n","Class 0 size is 365 times Class 1 size.\n","Avg precision score:  0.8843212711983476\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 366 times Class 1 size.\n","Avg precision score:  0.8907234304426123\n","Avg recall score:  0.5832907075873829\n","------------------------------------\n","Class 0 size is 367 times Class 1 size.\n","Avg precision score:  0.8908208833772744\n","Avg recall score:  0.5803921568627451\n","------------------------------------\n","Class 0 size is 368 times Class 1 size.\n","Avg precision score:  0.8954956472099329\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 369 times Class 1 size.\n","Avg precision score:  0.8879484101332841\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 370 times Class 1 size.\n","Avg precision score:  0.8868662751516319\n","Avg recall score:  0.6036658141517476\n","------------------------------------\n","Class 0 size is 371 times Class 1 size.\n","Avg precision score:  0.8851195862960569\n","Avg recall score:  0.592071611253197\n","------------------------------------\n","Class 0 size is 372 times Class 1 size.\n","Avg precision score:  0.8845665106161631\n","Avg recall score:  0.5891304347826087\n","------------------------------------\n","Class 0 size is 373 times Class 1 size.\n","Avg precision score:  0.8884187241330098\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 374 times Class 1 size.\n","Avg precision score:  0.8829996699263987\n","Avg recall score:  0.5803069053708441\n","------------------------------------\n","Class 0 size is 375 times Class 1 size.\n","Avg precision score:  0.8820821752768641\n","Avg recall score:  0.5948849104859335\n","------------------------------------\n","Class 0 size is 376 times Class 1 size.\n","Avg precision score:  0.8879484101332841\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 377 times Class 1 size.\n","Avg precision score:  0.879707113426295\n","Avg recall score:  0.5832907075873829\n","------------------------------------\n","Class 0 size is 378 times Class 1 size.\n","Avg precision score:  0.8838045663609574\n","Avg recall score:  0.5832907075873829\n","------------------------------------\n","Class 0 size is 379 times Class 1 size.\n","Avg precision score:  0.8844793301936159\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 380 times Class 1 size.\n","Avg precision score:  0.891887804072678\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 381 times Class 1 size.\n","Avg precision score:  0.8884187241330098\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 382 times Class 1 size.\n","Avg precision score:  0.8927519795300951\n","Avg recall score:  0.589087809036658\n","------------------------------------\n","Class 0 size is 383 times Class 1 size.\n","Avg precision score:  0.8891590983537873\n","Avg recall score:  0.5948849104859335\n","------------------------------------\n","Class 0 size is 384 times Class 1 size.\n","Avg precision score:  0.8838509571986218\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 385 times Class 1 size.\n","Avg precision score:  0.8907234304426123\n","Avg recall score:  0.5832907075873829\n","------------------------------------\n","Class 0 size is 386 times Class 1 size.\n","Avg precision score:  0.889636871762369\n","Avg recall score:  0.5948422847399829\n","------------------------------------\n","Class 0 size is 387 times Class 1 size.\n","Avg precision score:  0.8871155873053572\n","Avg recall score:  0.5832907075873829\n","------------------------------------\n","Class 0 size is 388 times Class 1 size.\n","Avg precision score:  0.8880704909125962\n","Avg recall score:  0.5862318840579711\n","------------------------------------\n","Class 0 size is 389 times Class 1 size.\n","Avg precision score:  0.8838045663609574\n","Avg recall score:  0.5832907075873829\n","------------------------------------\n","Class 0 size is 390 times Class 1 size.\n","Avg precision score:  0.8884187241330098\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 391 times Class 1 size.\n","Avg precision score:  0.8877439603003513\n","Avg recall score:  0.5832907075873829\n","------------------------------------\n","Class 0 size is 392 times Class 1 size.\n","Avg precision score:  0.8884187241330098\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 393 times Class 1 size.\n","Avg precision score:  0.8954956472099329\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 394 times Class 1 size.\n","Avg precision score:  0.8877439603003513\n","Avg recall score:  0.5832907075873829\n","------------------------------------\n","Class 0 size is 395 times Class 1 size.\n","Avg precision score:  0.8884187241330098\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 396 times Class 1 size.\n","Avg precision score:  0.8910874839446269\n","Avg recall score:  0.5803921568627451\n","------------------------------------\n","Class 0 size is 397 times Class 1 size.\n","Avg precision score:  0.891556253270539\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 398 times Class 1 size.\n","Avg precision score:  0.890869653049055\n","Avg recall score:  0.5832480818414322\n","------------------------------------\n","Class 0 size is 399 times Class 1 size.\n","Avg precision score:  0.8844793301936159\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 400 times Class 1 size.\n","Avg precision score:  0.8954956472099329\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 401 times Class 1 size.\n","Avg precision score:  0.8868814894378805\n","Avg recall score:  0.5803921568627451\n","------------------------------------\n","Class 0 size is 402 times Class 1 size.\n","Avg precision score:  0.8954956472099329\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 403 times Class 1 size.\n","Avg precision score:  0.8838045663609574\n","Avg recall score:  0.5832907075873829\n","------------------------------------\n","Class 0 size is 404 times Class 1 size.\n","Avg precision score:  0.8911474139895192\n","Avg recall score:  0.5833333333333334\n","------------------------------------\n","Class 0 size is 405 times Class 1 size.\n","Avg precision score:  0.8913592628464624\n","Avg recall score:  0.5832480818414322\n","------------------------------------\n","Class 0 size is 406 times Class 1 size.\n","Avg precision score:  0.8912130402400195\n","Avg recall score:  0.5832907075873829\n","------------------------------------\n","Class 0 size is 407 times Class 1 size.\n","Avg precision score:  0.8895800627943485\n","Avg recall score:  0.571611253196931\n","------------------------------------\n","Class 0 size is 408 times Class 1 size.\n","Avg precision score:  0.8906623138765996\n","Avg recall score:  0.5774936061381075\n","------------------------------------\n","Class 0 size is 409 times Class 1 size.\n","Avg precision score:  0.8895442876325935\n","Avg recall score:  0.571696504688832\n","------------------------------------\n","Class 0 size is 410 times Class 1 size.\n","Avg precision score:  0.8914956472099329\n","Avg recall score:  0.5832907075873829\n","------------------------------------\n","Class 0 size is 411 times Class 1 size.\n","Avg precision score:  0.8867229199372056\n","Avg recall score:  0.5774936061381075\n","------------------------------------\n","Class 0 size is 412 times Class 1 size.\n","Avg precision score:  0.8884187241330098\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 413 times Class 1 size.\n","Avg precision score:  0.8878901829067942\n","Avg recall score:  0.5832480818414322\n","------------------------------------\n","Class 0 size is 414 times Class 1 size.\n","Avg precision score:  0.887966235445227\n","Avg recall score:  0.5832907075873829\n","------------------------------------\n","Class 0 size is 415 times Class 1 size.\n","Avg precision score:  0.8872154190741357\n","Avg recall score:  0.5803495311167947\n","------------------------------------\n","Class 0 size is 416 times Class 1 size.\n","Avg precision score:  0.8867229199372056\n","Avg recall score:  0.5774936061381075\n","------------------------------------\n","Class 0 size is 417 times Class 1 size.\n","Avg precision score:  0.8903007693449652\n","Avg recall score:  0.5803921568627451\n","------------------------------------\n","Class 0 size is 418 times Class 1 size.\n","Avg precision score:  0.8877439603003513\n","Avg recall score:  0.5832907075873829\n","------------------------------------\n","Class 0 size is 419 times Class 1 size.\n","Avg precision score:  0.890219051465252\n","Avg recall score:  0.5745950554134698\n","------------------------------------\n","Class 0 size is 420 times Class 1 size.\n","Avg precision score:  0.8906623138765996\n","Avg recall score:  0.5774936061381075\n","------------------------------------\n","Class 0 size is 421 times Class 1 size.\n","Avg precision score:  0.8895442876325935\n","Avg recall score:  0.571696504688832\n","------------------------------------\n","Class 0 size is 422 times Class 1 size.\n","Avg precision score:  0.8877439603003513\n","Avg recall score:  0.5832907075873829\n","------------------------------------\n","Class 0 size is 423 times Class 1 size.\n","Avg precision score:  0.8948289805432662\n","Avg recall score:  0.5803921568627451\n","------------------------------------\n","Class 0 size is 424 times Class 1 size.\n","Avg precision score:  0.8867557529578436\n","Avg recall score:  0.5773657289002557\n","------------------------------------\n","Class 0 size is 425 times Class 1 size.\n","Avg precision score:  0.8941043428621068\n","Avg recall score:  0.5745950554134698\n","------------------------------------\n","Class 0 size is 426 times Class 1 size.\n","Avg precision score:  0.8908208833772744\n","Avg recall score:  0.5803921568627451\n","------------------------------------\n","Class 0 size is 427 times Class 1 size.\n","Avg precision score:  0.8877439603003513\n","Avg recall score:  0.5832907075873829\n","------------------------------------\n","Class 0 size is 428 times Class 1 size.\n","Avg precision score:  0.8948289805432662\n","Avg recall score:  0.5803921568627451\n","------------------------------------\n","Class 0 size is 429 times Class 1 size.\n","Avg precision score:  0.8895800627943485\n","Avg recall score:  0.571611253196931\n","------------------------------------\n","Class 0 size is 430 times Class 1 size.\n","Avg precision score:  0.8877439603003513\n","Avg recall score:  0.5832907075873829\n","------------------------------------\n","Class 0 size is 431 times Class 1 size.\n","Avg precision score:  0.8900068899274446\n","Avg recall score:  0.5745950554134698\n","------------------------------------\n","Class 0 size is 432 times Class 1 size.\n","Avg precision score:  0.8837927299721319\n","Avg recall score:  0.5832480818414322\n","------------------------------------\n","Class 0 size is 433 times Class 1 size.\n","Avg precision score:  0.8941043428621068\n","Avg recall score:  0.5745950554134698\n","------------------------------------\n","Class 0 size is 434 times Class 1 size.\n","Avg precision score:  0.8908208833772744\n","Avg recall score:  0.5803921568627451\n","------------------------------------\n","Class 0 size is 435 times Class 1 size.\n","Avg precision score:  0.8888035848685704\n","Avg recall score:  0.5687553282182438\n","------------------------------------\n","Class 0 size is 436 times Class 1 size.\n","Avg precision score:  0.8895442876325935\n","Avg recall score:  0.571696504688832\n","------------------------------------\n","Class 0 size is 437 times Class 1 size.\n","Avg precision score:  0.8908814894378804\n","Avg recall score:  0.5832907075873829\n","------------------------------------\n","Class 0 size is 438 times Class 1 size.\n","Avg precision score:  0.8884187241330098\n","Avg recall score:  0.5861892583120204\n","------------------------------------\n","Class 0 size is 439 times Class 1 size.\n","Avg precision score:  0.8872154190741357\n","Avg recall score:  0.5803495311167947\n","------------------------------------\n","Class 0 size is 440 times Class 1 size.\n","Avg precision score:  0.8908208833772744\n","Avg recall score:  0.5803921568627451\n","------------------------------------\n","Class 0 size is 441 times Class 1 size.\n","Avg precision score:  0.8890157464063779\n","Avg recall score:  0.5687553282182438\n","------------------------------------\n","Class 0 size is 442 times Class 1 size.\n","Avg precision score:  0.8901307891577683\n","Avg recall score:  0.5774083546462063\n","------------------------------------\n","Class 0 size is 443 times Class 1 size.\n","Avg precision score:  0.8934295790294483\n","Avg recall score:  0.571696504688832\n","------------------------------------\n","Class 0 size is 444 times Class 1 size.\n","Avg precision score:  0.8838045663609574\n","Avg recall score:  0.5832907075873829\n","------------------------------------\n","Class 0 size is 445 times Class 1 size.\n","Avg precision score:  0.8934295790294483\n","Avg recall score:  0.571696504688832\n","------------------------------------\n","Class 0 size is 446 times Class 1 size.\n","Avg precision score:  0.8934295790294483\n","Avg recall score:  0.571696504688832\n","------------------------------------\n","Class 0 size is 447 times Class 1 size.\n","Avg precision score:  0.8895442876325935\n","Avg recall score:  0.571696504688832\n","------------------------------------\n","Class 0 size is 448 times Class 1 size.\n","Avg precision score:  0.8934295790294483\n","Avg recall score:  0.571696504688832\n","------------------------------------\n","Class 0 size is 449 times Class 1 size.\n","Avg precision score:  0.8893304690297171\n","Avg recall score:  0.571611253196931\n","------------------------------------\n","Class 0 size is 450 times Class 1 size.\n","Avg precision score:  0.8878813164574272\n","Avg recall score:  0.5629156010230179\n","------------------------------------\n","Class 0 size is 451 times Class 1 size.\n","Avg precision score:  0.8872914716125685\n","Avg recall score:  0.5803921568627451\n","------------------------------------\n","Class 0 size is 452 times Class 1 size.\n","Avg precision score:  0.8941542167106077\n","Avg recall score:  0.5774936061381075\n","------------------------------------\n","Class 0 size is 453 times Class 1 size.\n","Avg precision score:  0.8941043428621068\n","Avg recall score:  0.5745950554134698\n","------------------------------------\n","Class 0 size is 454 times Class 1 size.\n","Avg precision score:  0.8934295790294483\n","Avg recall score:  0.571696504688832\n","------------------------------------\n","Class 0 size is 455 times Class 1 size.\n","Avg precision score:  0.8888035848685704\n","Avg recall score:  0.5687553282182438\n","------------------------------------\n","Class 0 size is 456 times Class 1 size.\n","Avg precision score:  0.8934295790294483\n","Avg recall score:  0.571696504688832\n","------------------------------------\n","Class 0 size is 457 times Class 1 size.\n","Avg precision score:  0.8868839843629759\n","Avg recall score:  0.5774083546462063\n","------------------------------------\n","Class 0 size is 458 times Class 1 size.\n","Avg precision score:  0.8934295790294483\n","Avg recall score:  0.571696504688832\n","------------------------------------\n","Class 0 size is 459 times Class 1 size.\n","Avg precision score:  0.8890157464063779\n","Avg recall score:  0.5687553282182438\n","------------------------------------\n","Class 0 size is 460 times Class 1 size.\n","Avg precision score:  0.8864733261725742\n","Avg recall score:  0.5774936061381075\n","------------------------------------\n","Class 0 size is 461 times Class 1 size.\n","Avg precision score:  0.8872914716125685\n","Avg recall score:  0.5803921568627451\n","------------------------------------\n","Class 0 size is 462 times Class 1 size.\n","Avg precision score:  0.8906844990138039\n","Avg recall score:  0.5803495311167947\n","------------------------------------\n","Class 0 size is 463 times Class 1 size.\n","Avg precision score:  0.8898841788857526\n","Avg recall score:  0.5745524296675193\n","------------------------------------\n","Class 0 size is 464 times Class 1 size.\n","Avg precision score:  0.8890157464063779\n","Avg recall score:  0.5687553282182438\n","------------------------------------\n","Class 0 size is 465 times Class 1 size.\n","Avg precision score:  0.8868208833772744\n","Avg recall score:  0.5774936061381075\n","------------------------------------\n","Class 0 size is 466 times Class 1 size.\n","Avg precision score:  0.8935758016358912\n","Avg recall score:  0.5716538789428816\n","------------------------------------\n","Class 0 size is 467 times Class 1 size.\n","Avg precision score:  0.8936256754843921\n","Avg recall score:  0.5745524296675193\n","------------------------------------\n","Class 0 size is 468 times Class 1 size.\n","Avg precision score:  0.8941043428621068\n","Avg recall score:  0.5745950554134698\n","------------------------------------\n","Class 0 size is 469 times Class 1 size.\n","Avg precision score:  0.8860809891251851\n","Avg recall score:  0.5744671781756181\n","------------------------------------\n","Class 0 size is 470 times Class 1 size.\n","Avg precision score:  0.8923473279471972\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 471 times Class 1 size.\n","Avg precision score:  0.8937996067815297\n","Avg recall score:  0.5745950554134698\n","------------------------------------\n","Class 0 size is 472 times Class 1 size.\n","Avg precision score:  0.8878813164574272\n","Avg recall score:  0.5629156010230179\n","------------------------------------\n","Class 0 size is 473 times Class 1 size.\n","Avg precision score:  0.8871632402074361\n","Avg recall score:  0.5803921568627451\n","------------------------------------\n","Class 0 size is 474 times Class 1 size.\n","Avg precision score:  0.8934295790294483\n","Avg recall score:  0.571696504688832\n","------------------------------------\n","Class 0 size is 475 times Class 1 size.\n","Avg precision score:  0.8895442876325935\n","Avg recall score:  0.571696504688832\n","------------------------------------\n","Class 0 size is 476 times Class 1 size.\n","Avg precision score:  0.8934295790294483\n","Avg recall score:  0.571696504688832\n","------------------------------------\n","Class 0 size is 477 times Class 1 size.\n","Avg precision score:  0.8937467294610151\n","Avg recall score:  0.5745098039215686\n","------------------------------------\n","Class 0 size is 478 times Class 1 size.\n","Avg precision score:  0.8889635675396784\n","Avg recall score:  0.5687979539641944\n","------------------------------------\n","Class 0 size is 479 times Class 1 size.\n","Avg precision score:  0.8934295790294483\n","Avg recall score:  0.571696504688832\n","------------------------------------\n","Class 0 size is 480 times Class 1 size.\n","Avg precision score:  0.8923473279471972\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 481 times Class 1 size.\n","Avg precision score:  0.8930719656283566\n","Avg recall score:  0.571611253196931\n","------------------------------------\n","Class 0 size is 482 times Class 1 size.\n","Avg precision score:  0.8935734966176925\n","Avg recall score:  0.5745950554134698\n","------------------------------------\n","Class 0 size is 483 times Class 1 size.\n","Avg precision score:  0.8917105616127564\n","Avg recall score:  0.5629582267689685\n","------------------------------------\n","Class 0 size is 484 times Class 1 size.\n","Avg precision score:  0.8929010378032327\n","Avg recall score:  0.5687553282182438\n","------------------------------------\n","Class 0 size is 485 times Class 1 size.\n","Avg precision score:  0.8895442876325935\n","Avg recall score:  0.571696504688832\n","------------------------------------\n","Class 0 size is 486 times Class 1 size.\n","Avg precision score:  0.8929010378032327\n","Avg recall score:  0.5687553282182438\n","------------------------------------\n","Class 0 size is 487 times Class 1 size.\n","Avg precision score:  0.8929010378032327\n","Avg recall score:  0.5687553282182438\n","------------------------------------\n","Class 0 size is 488 times Class 1 size.\n","Avg precision score:  0.8917666078542819\n","Avg recall score:  0.5629156010230179\n","------------------------------------\n","Class 0 size is 489 times Class 1 size.\n","Avg precision score:  0.8923473279471972\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 490 times Class 1 size.\n","Avg precision score:  0.8866617092181002\n","Avg recall score:  0.5774083546462063\n","------------------------------------\n","Class 0 size is 491 times Class 1 size.\n","Avg precision score:  0.8934295790294483\n","Avg recall score:  0.571696504688832\n","------------------------------------\n","Class 0 size is 492 times Class 1 size.\n","Avg precision score:  0.8935758016358912\n","Avg recall score:  0.5716538789428816\n","------------------------------------\n","Class 0 size is 493 times Class 1 size.\n","Avg precision score:  0.8929010378032327\n","Avg recall score:  0.5687553282182438\n","------------------------------------\n","Class 0 size is 494 times Class 1 size.\n","Avg precision score:  0.8941542167106077\n","Avg recall score:  0.5774936061381075\n","------------------------------------\n","Class 0 size is 495 times Class 1 size.\n","Avg precision score:  0.8923473279471972\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 496 times Class 1 size.\n","Avg precision score:  0.8884620365503425\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 497 times Class 1 size.\n","Avg precision score:  0.8934295790294483\n","Avg recall score:  0.571696504688832\n","------------------------------------\n","Class 0 size is 498 times Class 1 size.\n","Avg precision score:  0.8884620365503425\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 499 times Class 1 size.\n","Avg precision score:  0.8923473279471972\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 500 times Class 1 size.\n","Avg precision score:  0.8939136326721142\n","Avg recall score:  0.5774936061381075\n","------------------------------------\n","Class 0 size is 501 times Class 1 size.\n","Avg precision score:  0.8921898002498898\n","Avg recall score:  0.5658567774936062\n","------------------------------------\n","Class 0 size is 502 times Class 1 size.\n","Avg precision score:  0.8929010378032327\n","Avg recall score:  0.5687553282182438\n","------------------------------------\n","Class 0 size is 503 times Class 1 size.\n","Avg precision score:  0.8923473279471972\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 504 times Class 1 size.\n","Avg precision score:  0.8917666078542819\n","Avg recall score:  0.5629156010230179\n","------------------------------------\n","Class 0 size is 505 times Class 1 size.\n","Avg precision score:  0.8917666078542821\n","Avg recall score:  0.5628729752770674\n","------------------------------------\n","Class 0 size is 506 times Class 1 size.\n","Avg precision score:  0.8923473279471972\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 507 times Class 1 size.\n","Avg precision score:  0.8934295790294483\n","Avg recall score:  0.571696504688832\n","------------------------------------\n","Class 0 size is 508 times Class 1 size.\n","Avg precision score:  0.8923473279471972\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 509 times Class 1 size.\n","Avg precision score:  0.8934295790294483\n","Avg recall score:  0.571696504688832\n","------------------------------------\n","Class 0 size is 510 times Class 1 size.\n","Avg precision score:  0.8895442876325935\n","Avg recall score:  0.571696504688832\n","------------------------------------\n","Class 0 size is 511 times Class 1 size.\n","Avg precision score:  0.888797073853465\n","Avg recall score:  0.5687979539641944\n","------------------------------------\n","Class 0 size is 512 times Class 1 size.\n","Avg precision score:  0.8934295790294483\n","Avg recall score:  0.571696504688832\n","------------------------------------\n","Class 0 size is 513 times Class 1 size.\n","Avg precision score:  0.8910553703009392\n","Avg recall score:  0.5600170502983801\n","------------------------------------\n","Class 0 size is 514 times Class 1 size.\n","Avg precision score:  0.890474650208024\n","Avg recall score:  0.5570758738277919\n","------------------------------------\n","Class 0 size is 515 times Class 1 size.\n","Avg precision score:  0.8923473279471972\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 516 times Class 1 size.\n","Avg precision score:  0.8884620365503425\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 517 times Class 1 size.\n","Avg precision score:  0.8923473279471972\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 518 times Class 1 size.\n","Avg precision score:  0.8917666078542819\n","Avg recall score:  0.5629156010230179\n","------------------------------------\n","Class 0 size is 519 times Class 1 size.\n","Avg precision score:  0.8916360903938543\n","Avg recall score:  0.5629156010230179\n","------------------------------------\n","Class 0 size is 520 times Class 1 size.\n","Avg precision score:  0.8862092205303174\n","Avg recall score:  0.5745098039215686\n","------------------------------------\n","Class 0 size is 521 times Class 1 size.\n","Avg precision score:  0.8923473279471972\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 522 times Class 1 size.\n","Avg precision score:  0.8884620365503425\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 523 times Class 1 size.\n","Avg precision score:  0.8934295790294483\n","Avg recall score:  0.571696504688832\n","------------------------------------\n","Class 0 size is 524 times Class 1 size.\n","Avg precision score:  0.8923473279471972\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 525 times Class 1 size.\n","Avg precision score:  0.8923473279471972\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 526 times Class 1 size.\n","Avg precision score:  0.8917666078542819\n","Avg recall score:  0.5629156010230179\n","------------------------------------\n","Class 0 size is 527 times Class 1 size.\n","Avg precision score:  0.8923473279471972\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 528 times Class 1 size.\n","Avg precision score:  0.8917666078542819\n","Avg recall score:  0.5629156010230179\n","------------------------------------\n","Class 0 size is 529 times Class 1 size.\n","Avg precision score:  0.8884620365503425\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 530 times Class 1 size.\n","Avg precision score:  0.8923473279471972\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 531 times Class 1 size.\n","Avg precision score:  0.8934295790294483\n","Avg recall score:  0.571696504688832\n","------------------------------------\n","Class 0 size is 532 times Class 1 size.\n","Avg precision score:  0.8923473279471972\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 533 times Class 1 size.\n","Avg precision score:  0.88890529896169\n","Avg recall score:  0.5687127024722932\n","------------------------------------\n","Class 0 size is 534 times Class 1 size.\n","Avg precision score:  0.8923473279471972\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 535 times Class 1 size.\n","Avg precision score:  0.8911568517567211\n","Avg recall score:  0.5600170502983801\n","------------------------------------\n","Class 0 size is 536 times Class 1 size.\n","Avg precision score:  0.8910553703009392\n","Avg recall score:  0.5600170502983801\n","------------------------------------\n","Class 0 size is 537 times Class 1 size.\n","Avg precision score:  0.8884620365503425\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 538 times Class 1 size.\n","Avg precision score:  0.8905761316638058\n","Avg recall score:  0.5570758738277919\n","------------------------------------\n","Class 0 size is 539 times Class 1 size.\n","Avg precision score:  0.8921376213831902\n","Avg recall score:  0.5658994032395567\n","------------------------------------\n","Class 0 size is 540 times Class 1 size.\n","Avg precision score:  0.8923473279471972\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 541 times Class 1 size.\n","Avg precision score:  0.8911568517567211\n","Avg recall score:  0.5600170502983801\n","------------------------------------\n","Class 0 size is 542 times Class 1 size.\n","Avg precision score:  0.8916090801569746\n","Avg recall score:  0.5629582267689685\n","------------------------------------\n","Class 0 size is 543 times Class 1 size.\n","Avg precision score:  0.8904456142033782\n","Avg recall score:  0.5571184995737426\n","------------------------------------\n","Class 0 size is 544 times Class 1 size.\n","Avg precision score:  0.8910553703009392\n","Avg recall score:  0.5600170502983801\n","------------------------------------\n","Class 0 size is 545 times Class 1 size.\n","Avg precision score:  0.8911568517567211\n","Avg recall score:  0.5600170502983801\n","------------------------------------\n","Class 0 size is 546 times Class 1 size.\n","Avg precision score:  0.8880385113834592\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 547 times Class 1 size.\n","Avg precision score:  0.8917666078542821\n","Avg recall score:  0.5628729752770674\n","------------------------------------\n","Class 0 size is 548 times Class 1 size.\n","Avg precision score:  0.8923473279471972\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 549 times Class 1 size.\n","Avg precision score:  0.889864894110463\n","Avg recall score:  0.5541773231031544\n","------------------------------------\n","Class 0 size is 550 times Class 1 size.\n","Avg precision score:  0.8923473279471972\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 551 times Class 1 size.\n","Avg precision score:  0.8910553703009392\n","Avg recall score:  0.5600170502983801\n","------------------------------------\n","Class 0 size is 552 times Class 1 size.\n","Avg precision score:  0.8911568517567211\n","Avg recall score:  0.5600170502983801\n","------------------------------------\n","Class 0 size is 553 times Class 1 size.\n","Avg precision score:  0.8904456142033782\n","Avg recall score:  0.5571184995737426\n","------------------------------------\n","Class 0 size is 554 times Class 1 size.\n","Avg precision score:  0.8911568517567211\n","Avg recall score:  0.5600170502983801\n","------------------------------------\n","Class 0 size is 555 times Class 1 size.\n","Avg precision score:  0.8923473279471972\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 556 times Class 1 size.\n","Avg precision score:  0.8910553703009392\n","Avg recall score:  0.5599744245524296\n","------------------------------------\n","Class 0 size is 557 times Class 1 size.\n","Avg precision score:  0.8923473279471972\n","Avg recall score:  0.5658141517476556\n","------------------------------------\n","Class 0 size is 558 times Class 1 size.\n","Avg precision score:  0.8911568517567211\n","Avg recall score:  0.5600170502983801\n","------------------------------------\n","Class 0 size is 559 times Class 1 size.\n","Avg precision score:  0.8904456142033782\n","Avg recall score:  0.5571184995737426\n","------------------------------------\n","Class 0 size is 560 times Class 1 size.\n","Avg precision score:  0.8909993240594136\n","Avg recall score:  0.5600596760443308\n","------------------------------------\n","Class 0 size is 561 times Class 1 size.\n","Avg precision score:  0.8911568517567211\n","Avg recall score:  0.5600170502983801\n","------------------------------------\n","Class 0 size is 562 times Class 1 size.\n","Avg precision score:  0.8904456142033782\n","Avg recall score:  0.5571184995737426\n","------------------------------------\n","Class 0 size is 563 times Class 1 size.\n","Avg precision score:  0.8904456142033782\n","Avg recall score:  0.5571184995737426\n","------------------------------------\n","Class 0 size is 564 times Class 1 size.\n","Avg precision score:  0.8904456142033782\n","Avg recall score:  0.5571184995737426\n","------------------------------------\n","Class 0 size is 565 times Class 1 size.\n","Avg precision score:  0.8911568517567211\n","Avg recall score:  0.5600170502983801\n","------------------------------------\n","Class 0 size is 566 times Class 1 size.\n","Avg precision score:  0.8904456142033782\n","Avg recall score:  0.5571184995737426\n","------------------------------------\n","Class 0 size is 567 times Class 1 size.\n","Avg precision score:  0.8904456142033782\n","Avg recall score:  0.5571184995737426\n","------------------------------------\n","Class 0 size is 568 times Class 1 size.\n","Avg precision score:  0.8904456142033782\n","Avg recall score:  0.5571184995737426\n","------------------------------------\n","Class 0 size is 569 times Class 1 size.\n","Avg precision score:  0.8911568517567211\n","Avg recall score:  0.5600170502983801\n","------------------------------------\n","Class 0 size is 570 times Class 1 size.\n","Avg precision score:  0.889864894110463\n","Avg recall score:  0.5541773231031544\n","------------------------------------\n","Class 0 size is 571 times Class 1 size.\n","Avg precision score:  0.8904456142033782\n","Avg recall score:  0.5571184995737426\n","------------------------------------\n","Class 0 size is 572 times Class 1 size.\n","Avg precision score:  0.8911568517567211\n","Avg recall score:  0.5600170502983801\n","------------------------------------\n","Class 0 size is 573 times Class 1 size.\n","Avg precision score:  0.8904456142033782\n","Avg recall score:  0.5571184995737426\n","------------------------------------\n","Class 0 size is 574 times Class 1 size.\n","Avg precision score:  0.8904456142033782\n","Avg recall score:  0.5571184995737426\n","------------------------------------\n","Class 0 size is 575 times Class 1 size.\n","Avg precision score:  0.8904456142033782\n","Avg recall score:  0.5571184995737426\n","------------------------------------\n","Class 0 size is 576 times Class 1 size.\n","Avg precision score:  0.8904456142033782\n","Avg recall score:  0.5571184995737426\n","------------------------------------\n","Class 0 size is 577 times Class 1 size.\n","Avg precision score:  0.8904456142033782\n","Avg recall score:  0.5571184995737426\n"]}],"source":["# DO NOT RUN THIS CELL AGAIN\n","ratio = len(raw[raw.Class==0])//len(raw[raw.Class==1])\n","k_value = range(1, ratio+1, 1)\n","precisionList = [] \n","recallList = [] \n","diff = []\n","for i in k_value: \n","    prec, rec = SemiUnderSampling_LR(k=i, showFoldResult=False)\n","    precisionList.append(prec)\n","    recallList.append(rec)\n","    diff.append(prec-rec)\n","    "]},{"cell_type":"code","execution_count":57,"id":"da2c7b52","metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# DO NOT RUN THIS CELL AGAIN\n","plt.plot(k_value, precisionList, label='precision')\n","plt.plot(k_value, recallList, label='recall')\n","plt.ylabel('Score')\n","plt.xlabel('Size of Class 0 relative to Class 1')\n","plt.title('Precision-Recall tradeoff with different k')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":54,"id":"bb2616ed","metadata":{},"outputs":[],"source":["# DO NOT RUN THIS CELL AGAIN\n","def find_nearest(array, value): \n","    array = np.asarray(array)\n","    idx = (np.abs(array - value)).argmin()\n","    return idx"]},{"cell_type":"code","execution_count":55,"id":"0ef019f9","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Best precision-recall tradeoff is when Class 0 is 19 times Class 1.\n"]}],"source":["# DO NOT RUN THIS CELL AGAIN\n","min_idx = find_nearest(diff, 0)\n","print(f\"Best precision-recall tradeoff is when Class 0 is {min_idx} times Class 1.\")"]},{"cell_type":"markdown","id":"615e1ed7","metadata":{},"source":["## Gaussian Naive Bayes"]},{"cell_type":"markdown","id":"9726035a","metadata":{},"source":["### Model summary "]},{"cell_type":"markdown","id":"8d66a07a","metadata":{},"source":["\\begin{align}\n","p(y|data) = \\frac{p(data|y)*p(y)}{p(data)} \\\\\n","\n","p(y|data) \\propto p(data|y)*p(y)\n","\\end{align}\n","\n","Assuming all features $a_1, a_2,..., a_T$ of data are IID: \n","\\begin{align}\n","p(data|y) = p(a_1,..., a_T|y) = \\prod_{i=1}^T p(a_i|y)\n","\\end{align}\n","\n","To improve model simplicity, we can eliminate features that have similar distributions between Class 0 and Class 1. In other words, if $p(X_i|y1)$ ~ $p(X_i|y2)$, we can eliminate $X_i$ from the model because: \n","\n","\\begin{align}\n","p(y1|data) \\propto p(data|y1)*p(y1) = [\\prod_{i=1}^T p(x_i|y1)] * p(y1) \\\\ \n","\n","p(y2|data) \\propto p(data|y2)*p(y2) = [\\prod_{i=1}^T p(x_i|y2)] * p(y2) \n","\\end{align}\n","If $p(X_i|y1)$ ~ $p(X_i|y2)$, then the following ratio stays relatively the same. \n","\n","\\begin{align}\n","\\frac{p(y1|data)}{p(y2|data)} = \\frac{[\\prod_{i=1}^T p(x_i|y1)] * p(y1)}{[\\prod_{i=1}^T p(x_i|y2)] * p(y2)}\n","\\end{align}\n","\n","Or, the final classificaion is not much influenced by the removal of class $X_i$. "]},{"cell_type":"markdown","id":"da8061b6","metadata":{},"source":["### Model assumptions"]},{"cell_type":"markdown","id":"8a686706","metadata":{},"source":["- GNB assumes strong independence between features. However, in real life we don't usually have perfect independence, so we proceed anyways :) This assumption is why the model is named \"Naive\". \n","- GNB assumes the distributions of classes in each feature follows a Gaussian distribution --> this seems like a far reach for out data, because often we don't have normal distribution. But this is the best we can do for now :) \n","- From the above formula, we can tell that a heavily imbalanced data set like this will badly influence GNB's prediction as a blind guess of Class 0 will yields accuracy >= 99% (but this is useless for fraud detection purposes) --> need balancing data \n","    - Undersampling is preferred because oversampling from 500 observations to 23k observations means 99% fraud observations are synthetic data --> sus "]},{"cell_type":"markdown","id":"88c22009","metadata":{},"source":["### GNB on undersampled data"]},{"cell_type":"code","execution_count":56,"id":"bd717592","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold 0:\n","Undersampled data is balanced between classes.\n","GAUSSIAN NAIVE BAYES ON UNDERSAMPLED RAW DATA RESULTS\n","test set confusion matrix:\n"," [[ 6127 33678]\n"," [    0    68]]\n","recall score:  1.0\n","precision score:  0.002015053635986487\n","accuracy score:  0.15536829433451207\n","f1 score:  0.0040220027207665465\n","ROC AUC: 0.7500158862690913\n","Fold 1:\n","Undersampled data is balanced between classes.\n","GAUSSIAN NAIVE BAYES ON UNDERSAMPLED RAW DATA RESULTS\n","test set confusion matrix:\n"," [[ 6584 33220]\n"," [    0    69]]\n","recall score:  1.0\n","precision score:  0.0020727567664994445\n","accuracy score:  0.1668547638753041\n","f1 score:  0.004136938665387613\n","ROC AUC: 0.760413890381711\n","Fold 2:\n","Undersampled data is balanced between classes.\n","GAUSSIAN NAIVE BAYES ON UNDERSAMPLED RAW DATA RESULTS\n","test set confusion matrix:\n"," [[ 4805 34999]\n"," [    0    69]]\n","recall score:  1.0\n","precision score:  0.0019676057944564844\n","accuracy score:  0.12223810598650715\n","f1 score:  0.003927483848934172\n","ROC AUC: 0.7205557230429103\n","Fold 3:\n","Undersampled data is balanced between classes.\n","GAUSSIAN NAIVE BAYES ON UNDERSAMPLED RAW DATA RESULTS\n","test set confusion matrix:\n"," [[ 4101 35703]\n"," [    0    69]]\n","recall score:  1.0\n","precision score:  0.0019288829251928883\n","accuracy score:  0.10458204800240764\n","f1 score:  0.0038503389972378\n","ROC AUC: 0.6892887467430991\n","Fold 4:\n","Undersampled data is balanced between classes.\n","GAUSSIAN NAIVE BAYES ON UNDERSAMPLED RAW DATA RESULTS\n","test set confusion matrix:\n"," [[ 5391 34413]\n"," [    0    68]]\n","recall score:  1.0\n","precision score:  0.0019721005771294337\n","accuracy score:  0.13691312199036917\n","f1 score:  0.00393643810240528\n","ROC AUC: 0.7338868544101391\n","------------------------------------\n","Avg precision score:  0.001991279939852948\n","Avg recall score:  1.0\n"]}],"source":["cv4 = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n","cv4.get_n_splits(X_train_raw, y_train_raw)\n","precision_GNB_und = []\n","recall_GNB_und = [] \n","for i, (train_index, test_index) in enumerate(cv4.split(X_train_raw, y_train_raw)):\n","    print(f\"Fold {i}:\")\n","\n","    ## train_split and test_split will be train and test for the fold i\n","    ## Both train_split and test_split are raw.\n","    X_train_fold = X_train_raw.iloc[train_index]\n","    X_test_fold = X_train_raw.iloc[test_index]\n","    y_train_fold = y_train_raw.iloc[train_index]\n","    y_test_fold = y_train_raw.iloc[test_index]\n","\n","    # undersample the train set \n","    tmp = pd.concat([X_train_fold, y_train_fold], axis=1)\n","    fraud_index = np.array(tmp[tmp.Class==1].index)\n","    n_fraud = len(fraud_index) \n","\n","    genuine_index = np.array(tmp[tmp.Class==0].index)\n","    rus_genuine_index = np.array(np.random.choice(a=genuine_index, size=n_fraud, replace=False))\n","    rus_index = np.concatenate([rus_genuine_index, fraud_index])\n","    undersampled_df = tmp.loc[rus_index]\n","\n","    if(len(undersampled_df[undersampled_df.Class==0]) == len(undersampled_df[undersampled_df.Class==1])):\n","        print(\"Undersampled data is balanced between classes.\")\n","\n","    y_train_fold_und = undersampled_df['Class'].values \n","    X_train_fold_und = undersampled_df.drop(['Class'], axis=1)\n","\n","    # transform & rescale train and test \n","    X_train_fold_transform = transformer.fit_transform(X_train_fold_und)\n","    X_test_fold_transform = transformer.transform(deepcopy(X_test_fold))\n","    X_train_fold_transform, X_test_fold_transform = \\\n","        robust_scaler(X_train_fold_transform, X_test_fold_transform)\n","    \n","    # fit model\n","    y_und_GNB, y_und_GNB_proba = get_predictions(GaussianNB(),\n","                                                X_train_fold_transform, y_train_fold_und, X_test_fold_transform)\n","\n","    print('GAUSSIAN NAIVE BAYES ON UNDERSAMPLED RAW DATA RESULTS')\n","    fold_precision, fold_recall = print_scores(y_test_fold, y_und_GNB, y_und_GNB_proba)\n","    precision_GNB_und.append(fold_precision)\n","    recall_GNB_und.append(fold_recall)\n","\n","print('------------------------------------')\n","print(\"Avg precision score: \", np.array(precision_GNB_und).mean())\n","print(\"Avg recall score: \", np.array(recall_GNB_und).mean())"]},{"cell_type":"markdown","id":"8cf395cb","metadata":{},"source":["**Comment:** Very high recall, very low precision --> GNB flag almost every transaction as fraud :)"]},{"cell_type":"markdown","id":"27034486","metadata":{},"source":["# Final training & testing\n","From the previous validation result, LogReg on cleaned data and semi-undersampled raw data performs the best. \n","\n","We fit Logistic Regression on cleaned data and semi-undersampled raw data, and test the 2 models on X_test_final and y_test_final set. "]},{"cell_type":"markdown","id":"fbdb9c4c","metadata":{},"source":["## LogReg on cleaned data\n"]},{"cell_type":"code","execution_count":32,"id":"f36edec1","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["FINAL TEST: LOGISTIC REGRESSION ON CLEANED DATA\n","test set confusion matrix:\n"," [[85266    28]\n"," [   34   115]]\n","recall score:  0.7718120805369127\n","precision score:  0.8041958041958042\n","accuracy score:  0.9992743700478681\n","f1 score:  0.7876712328767123\n","ROC AUC: 0.9671686702905056\n"]}],"source":["# fit model \n","y_LR_cleaned_final, y_LR_cleaned_proba_final = \\\n","    get_predictions(LogisticRegression(C=0.01, penalty='l1', solver='liblinear'), \n","                    X_train_cleaned_transform, y_train_cleaned, X_test_final)\n","\n","print('FINAL TEST: LOGISTIC REGRESSION ON CLEANED DATA')\n","prec_LR_final, rec_LR_final = print_scores(y_test_final, y_LR_cleaned_final, y_LR_cleaned_proba_final)"]},{"cell_type":"markdown","id":"41b9f03d","metadata":{},"source":["## LogReg on semi-undersampled raw data \n","Let Class 0 size = 19 times Class 1 size"]},{"cell_type":"code","execution_count":31,"id":"282c12b4","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["FINAL TEST: LOGISTIC REGRESSION ON SEMI-UNDERSAMPLED RAW DATA\n","Class 0 size is 19 times the size of Class 1\n","test set confusion matrix:\n"," [[85262    32]\n"," [   30   119]]\n","recall score:  0.7986577181208053\n","precision score:  0.7880794701986755\n","accuracy score:  0.9992743700478681\n","f1 score:  0.7933333333333333\n","ROC AUC: 0.9649422612950422\n"]}],"source":["k = 19 \n","# undersample the train set \n","tmp = pd.concat([X_train_raw, y_train_raw], axis=1)\n","fraud_index = np.array(tmp[tmp.Class==1].index)\n","n_fraud = len(fraud_index)\n","\n","genuine_index = np.array(tmp[tmp.Class==0].index)\n","### size=k*n_fraud, we tune this k value to find the best\n","rus_genuine_index = np.array(np.random.choice(a=genuine_index, size=k*n_fraud, replace=False))\n","rus_index = np.concatenate([rus_genuine_index, fraud_index])\n","undersampled_df = tmp.loc[rus_index]\n","\n","y_train_semi = undersampled_df['Class'].values \n","X_train_semi = undersampled_df.drop(['Class'], axis=1)\n","\n","# transform & rescale train and test \n","X_train_semi_transform = transformer.fit_transform(X_train_semi)\n","X_test_fold_transform = transformer.transform(deepcopy(X_test_fold)) # ignore this\n","X_train_semi_transform, X_test_fold_transform = \\\n","    robust_scaler(X_train_semi_transform, X_test_fold_transform) # only care about X_train_semi_transform\n","\n","# fit model\n","y_semi_LR_final, y_semi_LR_proba_final = get_predictions(LogisticRegression(C=0.01, penalty='l1', solver='liblinear'),\n","                                    X_train_semi_transform, y_train_semi, X_test_final)\n","\n","print(f'FINAL TEST: LOGISTIC REGRESSION ON SEMI-UNDERSAMPLED RAW DATA')\n","print(f\"Class 0 size is {k} times the size of Class 1\")\n","prec_LRsemi_final, rec_LRsemi_final = print_scores(y_test_final, y_semi_LR_final, y_semi_LR_proba_final)"]}],"metadata":{"colab":{"collapsed_sections":["e5O7e2rsGYxt","60f3746a","8f0ef352","O4I9TjigMY9a","2r5pJ1BqMfDP","2e0fc8a0","8e0e14d9","606053f6","a9a4ed40"],"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":5}
